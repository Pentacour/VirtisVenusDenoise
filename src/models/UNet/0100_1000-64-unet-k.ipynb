{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "517443e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################\n",
    "# DESCRIPTION: Como d con mae\n",
    "#              \n",
    "# RESULTS:     \n",
    "#              \n",
    "##############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e744b44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# CONFIG & HYPERPARAMS\n",
    "######################\n",
    "\n",
    "import os\n",
    "\n",
    "class HyperParams:\n",
    "    pass\n",
    "\n",
    "IMG_PATH = \"C:/Projects/VenusDenoise/dataset/cases/64/0100_1000/\"\n",
    "\n",
    "hyperparams = HyperParams()\n",
    "hyperparams.IMG_WIDTH = 64\n",
    "hyperparams.IMG_HEIGHT = 64\n",
    "hyperparams.EPOCHS = 600 #10000\n",
    "hyperparams.BATCH_SIZE = 16\n",
    "hyperparams.START_NEURONS = 8 # UNET\n",
    "hyperparams.LOSS = 'mean_absolute_error'\n",
    "\n",
    "IMG_WIDTH = hyperparams.IMG_WIDTH\n",
    "IMG_HEIGHT = hyperparams.IMG_HEIGHT\n",
    "\n",
    "IMG_CASE = str(IMG_WIDTH) +  \"/0100_1000\"\n",
    "SAVED_MODEL = \"0100_1000-64-k\"\n",
    "\n",
    "IMG_PATH_VALID = IMG_PATH + \"validation/\"\n",
    "IMG_PATH_TEST = IMG_PATH + \"test/\"\n",
    "IMG_PATH_TRAIN = IMG_PATH\n",
    "\n",
    "DEST_TESTS = os.path.abspath(os.path.join('../../../out_tests/', SAVED_MODEL))\n",
    "\n",
    "class RadianceLimits:\n",
    "    pass\n",
    "radiance_limits = RadianceLimits()\n",
    "radiance_limits.noisy_min = 0\n",
    "radiance_limits.noisy_max = 0.0898\n",
    "radiance_limits.nitid_min = 0\n",
    "radiance_limits.nitid_max = 0.3248\n",
    "\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "#hyperparams.OPTIMIZER = Adam(learning_rate=0.0001)\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "hyperparams.OPTIMIZER = Nadam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1634ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# IMPORTS\n",
    "##################\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow \n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('../../support/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import DatasetUtilsTifF as dsutils\n",
    "import TrainModelC as train\n",
    "import ReportsK as reports\n",
    "import UnetI as model_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b516b30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 952571625201507590\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5722079232\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2931240224364560172\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:2b:00.0, compute capability: 8.6\"\n",
      "]\n",
      "Tensorflow version: 2.6.0\n",
      "Keras Version: 2.6.0\n",
      "GPU is available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tf.keras.__version__}\")\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4dda609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss=mean_absolute_error\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 8)    80          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 8)    584         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 8)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 8)    0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   1168        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 16)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16, 16, 16)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 32)   4640        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 32)   9248        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 32)     0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 8, 8, 32)     0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 8, 8, 64)     18496       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 8, 64)     36928       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 64)     0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 4, 4, 64)     0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 4, 128)    73856       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 4, 4, 128)    147584      conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 8, 8, 64)     73792       conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 128)    0           conv2d_transpose[0][0]           \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 8, 8, 128)    0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 64)     73792       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 64)     36928       conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 16, 16, 64)   36928       conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 96)   0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16, 16, 96)   0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 32)   27680       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 64)   18496       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 80)   0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 80)   0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 16)   11536       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 64, 64, 64)   9280        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 72)   0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64, 64, 72)   0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 8)    5192        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 8)    584         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 1)    9           conv2d_17[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 600,689\n",
      "Trainable params: 600,689\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Nadam',\n",
       " 'learning_rate': 0.0001,\n",
       " 'decay': 0.004,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'epsilon': 1e-07}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################\n",
    "# MODEL DEFINITION\n",
    "##################\n",
    "\n",
    "model = model_factory.buildModel(hyperparams)\n",
    "model.summary()\n",
    "model.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cf11c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read dataset. Path: C:/Projects/VenusDenoise/dataset/cases/64/0100_1000/\n",
      "Noisy files:9696\n",
      "Nitid files:9696\n",
      "Read dataset. Path: C:/Projects/VenusDenoise/dataset/cases/64/0100_1000/validation/\n",
      "Noisy files:2309\n",
      "Nitid files:2309\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# PREPARE DATA\n",
    "##################\n",
    "\n",
    "train_noisy_files, train_nitid_files, train_noisy, train_nitid = dsutils.readDataset( IMG_PATH_TRAIN, hyperparams.IMG_WIDTH, hyperparams.IMG_HEIGHT, radiance_limits)\n",
    "val_noisy_files, val_nitid_files, val_noisy, val_nitid = dsutils.readDataset( IMG_PATH_VALID, hyperparams.IMG_WIDTH, hyperparams.IMG_HEIGHT, radiance_limits)\n",
    "\n",
    "train_noisy, train_nitid = dsutils.reshapeDataset( train_noisy, train_nitid, hyperparams.IMG_WIDTH, hyperparams.IMG_HEIGHT )\n",
    "val_noisy, val_nitid = dsutils.reshapeDataset( val_noisy, val_nitid, hyperparams.IMG_WIDTH, hyperparams.IMG_HEIGHT )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88b591f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "606/606 [==============================] - 29s 35ms/step - loss: 0.1535 - val_loss: 0.1593\n",
      "Epoch 2/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.1440 - val_loss: 0.1593\n",
      "Epoch 3/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.1440 - val_loss: 0.1593\n",
      "Epoch 4/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.1440 - val_loss: 0.1593\n",
      "Epoch 5/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.1440 - val_loss: 0.1593\n",
      "Epoch 6/600\n",
      "606/606 [==============================] - 20s 34ms/step - loss: 0.0454 - val_loss: 0.0230\n",
      "Epoch 7/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0241 - val_loss: 0.0213\n",
      "Epoch 8/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0233 - val_loss: 0.0214\n",
      "Epoch 9/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0228 - val_loss: 0.0222\n",
      "Epoch 10/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0224 - val_loss: 0.0231\n",
      "Epoch 11/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0221 - val_loss: 0.0226\n",
      "Epoch 12/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0218 - val_loss: 0.0214\n",
      "Epoch 13/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0216 - val_loss: 0.0235\n",
      "Epoch 14/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0215 - val_loss: 0.0223\n",
      "Epoch 15/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0213 - val_loss: 0.0207\n",
      "Epoch 16/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0211 - val_loss: 0.0212\n",
      "Epoch 17/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0210 - val_loss: 0.0212\n",
      "Epoch 18/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0209 - val_loss: 0.0214\n",
      "Epoch 19/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0207 - val_loss: 0.0214\n",
      "Epoch 20/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0205 - val_loss: 0.0213\n",
      "Epoch 21/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0205 - val_loss: 0.0204\n",
      "Epoch 22/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0204 - val_loss: 0.0217\n",
      "Epoch 23/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0202 - val_loss: 0.0210\n",
      "Epoch 24/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0201 - val_loss: 0.0217\n",
      "Epoch 25/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0200 - val_loss: 0.0207\n",
      "Epoch 26/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0198 - val_loss: 0.0203\n",
      "Epoch 27/600\n",
      "606/606 [==============================] - 20s 34ms/step - loss: 0.0198 - val_loss: 0.0208\n",
      "Epoch 28/600\n",
      "606/606 [==============================] - 20s 34ms/step - loss: 0.0198 - val_loss: 0.0209\n",
      "Epoch 29/600\n",
      "606/606 [==============================] - 20s 34ms/step - loss: 0.0196 - val_loss: 0.0228\n",
      "Epoch 30/600\n",
      "606/606 [==============================] - 22s 36ms/step - loss: 0.0195 - val_loss: 0.0204\n",
      "Epoch 31/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0196 - val_loss: 0.0200\n",
      "Epoch 32/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0194 - val_loss: 0.0201\n",
      "Epoch 33/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0193 - val_loss: 0.0200\n",
      "Epoch 34/600\n",
      "606/606 [==============================] - 22s 36ms/step - loss: 0.0193 - val_loss: 0.0218\n",
      "Epoch 35/600\n",
      "606/606 [==============================] - 22s 36ms/step - loss: 0.0193 - val_loss: 0.0200\n",
      "Epoch 36/600\n",
      "606/606 [==============================] - 22s 36ms/step - loss: 0.0192 - val_loss: 0.0202\n",
      "Epoch 37/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0190 - val_loss: 0.0199\n",
      "Epoch 38/600\n",
      "606/606 [==============================] - 20s 34ms/step - loss: 0.0191 - val_loss: 0.0199\n",
      "Epoch 39/600\n",
      "606/606 [==============================] - 20s 34ms/step - loss: 0.0191 - val_loss: 0.0239\n",
      "Epoch 40/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0190 - val_loss: 0.0204\n",
      "Epoch 41/600\n",
      "606/606 [==============================] - 20s 34ms/step - loss: 0.0189 - val_loss: 0.0204\n",
      "Epoch 42/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0188 - val_loss: 0.0210\n",
      "Epoch 43/600\n",
      "606/606 [==============================] - 20s 34ms/step - loss: 0.0189 - val_loss: 0.0202\n",
      "Epoch 44/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0188 - val_loss: 0.0214\n",
      "Epoch 45/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0187 - val_loss: 0.0208\n",
      "Epoch 46/600\n",
      "606/606 [==============================] - 20s 34ms/step - loss: 0.0186 - val_loss: 0.0199\n",
      "Epoch 47/600\n",
      "606/606 [==============================] - 20s 34ms/step - loss: 0.0185 - val_loss: 0.0207\n",
      "Epoch 48/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0185 - val_loss: 0.0236\n",
      "Epoch 49/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0184 - val_loss: 0.0200\n",
      "Epoch 50/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0183 - val_loss: 0.0202\n",
      "Epoch 51/600\n",
      "606/606 [==============================] - 20s 34ms/step - loss: 0.0183 - val_loss: 0.0207\n",
      "Epoch 52/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0183 - val_loss: 0.0200\n",
      "Epoch 53/600\n",
      "606/606 [==============================] - 20s 34ms/step - loss: 0.0183 - val_loss: 0.0203\n",
      "Epoch 54/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0182 - val_loss: 0.0208\n",
      "Epoch 55/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0182 - val_loss: 0.0201\n",
      "Epoch 56/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0182 - val_loss: 0.0197\n",
      "Epoch 57/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0180 - val_loss: 0.0204\n",
      "Epoch 58/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0181 - val_loss: 0.0203\n",
      "Epoch 59/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0179 - val_loss: 0.0202\n",
      "Epoch 60/600\n",
      "606/606 [==============================] - 20s 34ms/step - loss: 0.0179 - val_loss: 0.0212\n",
      "Epoch 61/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0179 - val_loss: 0.0202\n",
      "Epoch 62/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0179 - val_loss: 0.0199\n",
      "Epoch 63/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0178 - val_loss: 0.0201\n",
      "Epoch 64/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0178 - val_loss: 0.0210\n",
      "Epoch 65/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0176 - val_loss: 0.0228\n",
      "Epoch 66/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0178 - val_loss: 0.0200\n",
      "Epoch 67/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0177 - val_loss: 0.0200\n",
      "Epoch 68/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0177 - val_loss: 0.0208\n",
      "Epoch 69/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0176 - val_loss: 0.0208\n",
      "Epoch 70/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0174 - val_loss: 0.0195\n",
      "Epoch 71/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0176 - val_loss: 0.0198\n",
      "Epoch 72/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0176 - val_loss: 0.0194\n",
      "Epoch 73/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0174 - val_loss: 0.0221\n",
      "Epoch 74/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0175 - val_loss: 0.0211\n",
      "Epoch 75/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0173 - val_loss: 0.0212\n",
      "Epoch 76/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0173 - val_loss: 0.0223\n",
      "Epoch 77/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0173 - val_loss: 0.0205\n",
      "Epoch 78/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0173 - val_loss: 0.0204\n",
      "Epoch 79/600\n",
      "606/606 [==============================] - 20s 34ms/step - loss: 0.0172 - val_loss: 0.0206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0172 - val_loss: 0.0205\n",
      "Epoch 81/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0171 - val_loss: 0.0222\n",
      "Epoch 82/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0172 - val_loss: 0.0198\n",
      "Epoch 83/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0172 - val_loss: 0.0209\n",
      "Epoch 84/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0170 - val_loss: 0.0231\n",
      "Epoch 85/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0170 - val_loss: 0.0209\n",
      "Epoch 86/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0169 - val_loss: 0.0210\n",
      "Epoch 87/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0168 - val_loss: 0.0215\n",
      "Epoch 88/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0169 - val_loss: 0.0200\n",
      "Epoch 89/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0168 - val_loss: 0.0208\n",
      "Epoch 90/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0168 - val_loss: 0.0215\n",
      "Epoch 91/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0168 - val_loss: 0.0203\n",
      "Epoch 92/600\n",
      "606/606 [==============================] - 20s 33ms/step - loss: 0.0168 - val_loss: 0.0207\n",
      "Train size:9696\n",
      "Valid.size:2309\n",
      "--- 1895.0919241905212 seconds ---\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# TRAIN MODEL\n",
    "##################\n",
    "hist = train.fit( model, hyperparams, train_noisy, train_nitid, val_noisy, val_nitid, patience = 20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8148067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##################\n",
    "# REPORTS\n",
    "##################\n",
    "\n",
    "reports.plotHistory( hist )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e495c47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black image found\n",
      "Black image found\n",
      "Images count =2309\n",
      "Best RMSENZ  =2171 (0.94)\n",
      "Best MAENZ   =2176 (0.94)\n",
      "Best Accuracy=2028 (0.88)\n",
      "RMSE-NZ  Pred=0.0243  Noisy=0.0943\n",
      "MAE-NZ   Pred=0.0208  Noisy=0.0904\n",
      "PSNR     Pred=20.3 dB Noisy=9.3 dB\n",
      "Accuracy Pred=0.40    Noisy=0.09\n",
      "SSM      Pred=0.95    Noisy=0.68\n",
      "HOG MSE  Pred=0.08    Noisy=0.12\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# PREDICTIONS\n",
    "##################\n",
    "ACCURACY_THRESHOLD = 0.01\n",
    "predictions_metrics, predictions_headers \\\n",
    "    = reports.calcPredictionMetrics( model, val_noisy, val_nitid, ACCURACY_THRESHOLD, \\\n",
    "                                    save_pred = True, save_path = DEST_TESTS, \\\n",
    "                                    noisy_files = val_noisy_files, nitid_files = val_nitid_files, \\\n",
    "                                    max_nitid= radiance_limits.nitid_max  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f9e4309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Projects\\VenusDenoise\\saves\\0100_1000-64-k\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(os.path.abspath(os.path.join('../../../saves/', SAVED_MODEL)), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5710f39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
