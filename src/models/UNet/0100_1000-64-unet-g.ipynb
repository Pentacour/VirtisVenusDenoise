{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "517443e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################\n",
    "# DESCRIPTION: \n",
    "#              \n",
    "# RESULTS:     \n",
    "#              \n",
    "##############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e744b44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# CONFIG & HYPERPARAMS\n",
    "######################\n",
    "\n",
    "import os\n",
    "\n",
    "class HyperParams:\n",
    "    pass\n",
    "\n",
    "IMG_PATH = \"C:/Projects/VenusDenoise/dataset/cases/64/0100_1000/\"\n",
    "\n",
    "hyperparams = HyperParams()\n",
    "hyperparams.IMG_WIDTH = 64\n",
    "hyperparams.IMG_HEIGHT = 64\n",
    "hyperparams.EPOCHS = 600 #10000\n",
    "hyperparams.BATCH_SIZE = 16\n",
    "hyperparams.START_NEURONS = 8 # UNET\n",
    "hyperparams.LOSS = 'mae_nz'\n",
    "\n",
    "IMG_WIDTH = hyperparams.IMG_WIDTH\n",
    "IMG_HEIGHT = hyperparams.IMG_HEIGHT\n",
    "\n",
    "IMG_CASE = str(IMG_WIDTH) +  \"/0100_1000\"\n",
    "SAVED_MODEL = \"0100_1000-64-g\"\n",
    "\n",
    "IMG_PATH_VALID = IMG_PATH + \"validation/\"\n",
    "IMG_PATH_TEST = IMG_PATH + \"test/\"\n",
    "IMG_PATH_TRAIN = IMG_PATH\n",
    "\n",
    "DEST_TESTS = os.path.abspath(os.path.join('../../../out_tests/', SAVED_MODEL))\n",
    "\n",
    "class RadianceLimits:\n",
    "    pass\n",
    "radiance_limits = RadianceLimits()\n",
    "radiance_limits.noisy_min = 0\n",
    "radiance_limits.noisy_max = 0.0898\n",
    "radiance_limits.nitid_min = 0\n",
    "radiance_limits.nitid_max = 0.3248\n",
    "\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "#hyperparams.OPTIMIZER = Adam(learning_rate=0.0001)\n",
    "#from tensorflow.keras.optimizers import Nadam\n",
    "#hyperparams.OPTIMIZER = Nadam(learning_rate=0.0001)\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "hyperparams.OPTIMIZER = RMSprop(learning_rate = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1634ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# IMPORTS\n",
    "##################\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow \n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('../../support/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import DatasetUtilsTifF as dsutils\n",
    "import TrainModelC as train\n",
    "import ReportsK as reports\n",
    "import UnetI as model_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b516b30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3808748020052011747\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1835670186\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4035245415667223007\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:2b:00.0, compute capability: 8.6\"\n",
      "]\n",
      "Tensorflow version: 2.6.0\n",
      "Keras Version: 2.6.0\n",
      "GPU is available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tf.keras.__version__}\")\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4dda609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 8)    80          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 8)    584         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 8)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 8)    0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   1168        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 16)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16, 16, 16)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 32)   4640        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 32)   9248        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 32)     0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 8, 8, 32)     0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 8, 8, 64)     18496       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 8, 64)     36928       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 64)     0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 4, 4, 64)     0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 4, 128)    73856       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 4, 4, 128)    147584      conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 8, 8, 64)     73792       conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 128)    0           conv2d_transpose[0][0]           \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 8, 8, 128)    0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 64)     73792       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 64)     36928       conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 16, 16, 64)   36928       conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 96)   0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16, 16, 96)   0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 32)   27680       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 64)   18496       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 80)   0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 80)   0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 16)   11536       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 64, 64, 64)   9280        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 72)   0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64, 64, 72)   0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 8)    5192        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 8)    584         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 1)    9           conv2d_17[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 600,689\n",
      "Trainable params: 600,689\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'RMSprop',\n",
       " 'learning_rate': 0.0001,\n",
       " 'decay': 0.0,\n",
       " 'rho': 0.9,\n",
       " 'momentum': 0.0,\n",
       " 'epsilon': 1e-07,\n",
       " 'centered': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################\n",
    "# MODEL DEFINITION\n",
    "##################\n",
    "\n",
    "model = model_factory.buildModel(hyperparams)\n",
    "model.summary()\n",
    "model.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cf11c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read dataset. Path: C:/Projects/VenusDenoise/dataset/cases/64/0100_1000/\n",
      "Noisy files:9696\n",
      "Nitid files:9696\n",
      "Read dataset. Path: C:/Projects/VenusDenoise/dataset/cases/64/0100_1000/validation/\n",
      "Noisy files:2309\n",
      "Nitid files:2309\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# PREPARE DATA\n",
    "##################\n",
    "\n",
    "train_noisy_files, train_nitid_files, train_noisy, train_nitid = dsutils.readDataset( IMG_PATH_TRAIN, hyperparams.IMG_WIDTH, hyperparams.IMG_HEIGHT, radiance_limits)\n",
    "val_noisy_files, val_nitid_files, val_noisy, val_nitid = dsutils.readDataset( IMG_PATH_VALID, hyperparams.IMG_WIDTH, hyperparams.IMG_HEIGHT, radiance_limits)\n",
    "\n",
    "train_noisy, train_nitid = dsutils.reshapeDataset( train_noisy, train_nitid, hyperparams.IMG_WIDTH, hyperparams.IMG_HEIGHT )\n",
    "val_noisy, val_nitid = dsutils.reshapeDataset( val_noisy, val_nitid, hyperparams.IMG_WIDTH, hyperparams.IMG_HEIGHT )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88b591f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "606/606 [==============================] - 24s 31ms/step - loss: 0.0056 - val_loss: 0.0019\n",
      "Epoch 2/600\n",
      "606/606 [==============================] - 18s 29ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 3/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 4/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 5/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 6/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 7/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 8/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 9/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 10/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 11/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 12/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 13/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 14/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 15/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 16/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 17/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 18/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 19/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 20/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 21/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 22/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 23/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 24/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 25/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 26/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 27/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 28/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 29/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 30/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 31/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 32/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 33/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 34/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 35/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 36/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 37/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 38/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 39/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 40/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 41/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 42/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 43/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 44/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 45/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 46/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 47/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 48/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 49/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 50/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 51/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 52/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 53/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 54/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 55/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 56/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 57/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 58/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 59/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 60/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 61/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 62/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 63/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 64/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 65/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 66/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 67/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 68/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 69/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 70/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 71/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 72/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 73/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 74/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 75/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 76/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 77/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 78/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 79/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 81/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 82/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 83/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 84/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 85/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 86/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 87/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 88/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 89/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 90/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 91/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 92/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 93/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 94/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 95/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 96/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 97/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 98/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 99/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 100/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 101/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 102/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 103/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 104/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 105/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 106/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 107/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 108/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 109/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 110/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 111/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 112/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 113/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 114/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 115/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 116/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 117/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 118/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 119/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 120/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 121/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 122/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 123/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 124/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 125/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 126/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 127/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 128/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 129/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 130/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 131/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 132/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 133/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 134/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 135/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 136/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 137/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 138/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 139/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 140/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 141/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 142/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 143/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 144/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 9.9617e-04 - val_loss: 0.0014\n",
      "Epoch 145/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 9.9984e-04 - val_loss: 0.0013\n",
      "Epoch 146/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 9.9836e-04 - val_loss: 0.0014\n",
      "Epoch 147/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 9.8915e-04 - val_loss: 0.0014\n",
      "Epoch 148/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 9.9477e-04 - val_loss: 0.0013\n",
      "Epoch 149/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 9.8994e-04 - val_loss: 0.0014\n",
      "Epoch 150/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 9.9298e-04 - val_loss: 0.0013\n",
      "Epoch 151/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 9.9285e-04 - val_loss: 0.0014\n",
      "Epoch 152/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 9.8681e-04 - val_loss: 0.0013\n",
      "Epoch 153/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 9.9102e-04 - val_loss: 0.0014\n",
      "Epoch 154/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 9.8913e-04 - val_loss: 0.0013\n",
      "Epoch 155/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 9.8667e-04 - val_loss: 0.0013\n",
      "Epoch 156/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 9.7935e-04 - val_loss: 0.0013\n",
      "Epoch 157/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606/606 [==============================] - 17s 28ms/step - loss: 9.7417e-04 - val_loss: 0.0014\n",
      "Epoch 158/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 9.8071e-04 - val_loss: 0.0013\n",
      "Epoch 159/600\n",
      "606/606 [==============================] - 17s 27ms/step - loss: 9.7655e-04 - val_loss: 0.0014\n",
      "Epoch 160/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 9.7759e-04 - val_loss: 0.0013\n",
      "Epoch 161/600\n",
      "606/606 [==============================] - 17s 28ms/step - loss: 9.7767e-04 - val_loss: 0.0013\n",
      "Train size:9696\n",
      "Valid.size:2309\n",
      "--- 2691.1589167118073 seconds ---\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# TRAIN MODEL\n",
    "##################\n",
    "hist = train.fit( model, hyperparams, train_noisy, train_nitid, val_noisy, val_nitid, patience = 100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8148067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##################\n",
    "# REPORTS\n",
    "##################\n",
    "\n",
    "reports.plotHistory( hist )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e495c47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black image found\n",
      "Black image found\n",
      "Images count =2309\n",
      "Best RMSENZ  =2088 (0.90)\n",
      "Best MAENZ   =2074 (0.90)\n",
      "Best Accuracy=1999 (0.87)\n",
      "RMSE-NZ  Pred=0.0246  Noisy=0.0943\n",
      "MAE-NZ   Pred=0.0209  Noisy=0.0904\n",
      "PSNR     Pred=19.7 dB Noisy=9.3 dB\n",
      "Accuracy Pred=0.38    Noisy=0.09\n",
      "SSM      Pred=0.94    Noisy=0.64\n",
      "HOG MSE  Pred=0.08    Noisy=0.12\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# PREDICTIONS\n",
    "##################\n",
    "ACCURACY_THRESHOLD = 0.01\n",
    "predictions_metrics, predictions_headers \\\n",
    "    = reports.calcPredictionMetrics( model, val_noisy, val_nitid, ACCURACY_THRESHOLD, \\\n",
    "                                    save_pred = True, save_path = DEST_TESTS, \\\n",
    "                                    noisy_files = val_noisy_files, nitid_files = val_nitid_files, \\\n",
    "                                    max_nitid= radiance_limits.nitid_max  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f9e4309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Projects\\VenusDenoise\\saves\\0100_1000-64-g\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(os.path.abspath(os.path.join('../../../saves/', SAVED_MODEL)), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb03b10e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
