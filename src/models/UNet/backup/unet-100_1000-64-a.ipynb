{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "517443e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################\n",
    "# DESCRIPTION: Entrenado con im√°genes Black. Se han eliminado de validation.\n",
    "#              \n",
    "# RESULTS:     \n",
    "#              \n",
    "##############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e744b44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# CONFIG & HYPERPARAMS\n",
    "######################\n",
    "\n",
    "class HyperParams:\n",
    "    pass\n",
    "\n",
    "IMG_PATH = \"C:/Projects/VenusDenoise/dataset/cases/64/0100_1000/\"\n",
    "\n",
    "hyperparams = HyperParams()\n",
    "hyperparams.IMG_WIDTH = 64\n",
    "hyperparams.IMG_HEIGHT = 64\n",
    "hyperparams.EPOCHS = 600 #10000\n",
    "hyperparams.BATCH_SIZE = 16\n",
    "hyperparams.START_NEURONS = 8 # UNET\n",
    "hyperparams.LOSS = 'mean_absolute_error'\n",
    "\n",
    "IMG_WIDTH = hyperparams.IMG_WIDTH\n",
    "IMG_HEIGHT = hyperparams.IMG_HEIGHT\n",
    "\n",
    "IMG_CASE = str(IMG_WIDTH) +  \"/0100_1000\"\n",
    "SAVED_MODEL = \"0100_1000-64-a\"\n",
    "\n",
    "IMG_PATH_VALID = IMG_PATH + \"validation/\"\n",
    "IMG_PATH_TEST = IMG_PATH + \"test/\"\n",
    "IMG_PATH_TRAIN = IMG_PATH\n",
    "\n",
    "DEST_TESTS = os.path.abspath(os.path.join('../../../out_tests/', SAVED_MODEL))\n",
    "\n",
    "class RadianceLimits:\n",
    "    pass\n",
    "radiance_limits = RadianceLimits()\n",
    "radiance_limits.noisy_min = 0\n",
    "radiance_limits.noisy_max = 0.0898\n",
    "radiance_limits.nitid_min = 0\n",
    "radiance_limits.nitid_max = 0.3248\n",
    "\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "#hyperparams.OPTIMIZER = Adam(learning_rate=0.0001)\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "hyperparams.OPTIMIZER = Nadam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1634ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# IMPORTS\n",
    "##################\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow \n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('../../support/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import DatasetUtilsTifF as dsutils\n",
    "import TrainModelB as train\n",
    "import ReportsK as reports\n",
    "\n",
    "#nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b516b30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10398728229552788684\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5462667264\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3346352947225267523\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:2b:00.0, compute capability: 8.6\"\n",
      "]\n",
      "Tensorflow version: 2.6.0\n",
      "Keras Version: 2.6.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tf.keras.__version__}\")\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d50ed68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4dda609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 8)    80          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 8)    584         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 8)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 8)    0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   1168        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 16)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16, 16, 16)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 32)   4640        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 32)   9248        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 32)     0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 8, 8, 32)     0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 8, 8, 64)     18496       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 8, 64)     36928       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 64)     0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 4, 4, 64)     0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 4, 128)    73856       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 4, 4, 128)    147584      conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 8, 8, 64)     73792       conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 128)    0           conv2d_transpose[0][0]           \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 8, 8, 128)    0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 64)     73792       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 64)     36928       conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 16, 16, 64)   36928       conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 96)   0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16, 16, 96)   0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 32)   27680       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 64)   18496       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 80)   0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 80)   0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 16)   11536       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 64, 64, 64)   9280        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 72)   0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64, 64, 72)   0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 8)    5192        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 8)    584         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 1)    9           conv2d_17[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 600,689\n",
      "Trainable params: 600,689\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Nadam',\n",
       " 'learning_rate': 0.0001,\n",
       " 'decay': 0.004,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'epsilon': 1e-07}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################\n",
    "# MODEL DEFINITION\n",
    "##################\n",
    "\n",
    "import UnetF as model_factory\n",
    "\n",
    "model = model_factory.buildModel(hyperparams)\n",
    "model.summary()\n",
    "model.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cf11c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read dataset. Path: C:/Projects/VenusDenoise/dataset/cases/64/0100_1000/\n",
      "Noisy files:9696\n",
      "Nitid files:9696\n",
      "Read dataset. Path: C:/Projects/VenusDenoise/dataset/cases/64/0100_1000/validation/\n",
      "Noisy files:2309\n",
      "Nitid files:2309\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# PREPARE DATA\n",
    "##################\n",
    "\n",
    "train_noisy_files, train_nitid_files, train_noisy, train_nitid = dsutils.readDataset( IMG_PATH_TRAIN, hyperparams.IMG_WIDTH, hyperparams.IMG_HEIGHT, radiance_limits)\n",
    "val_noisy_files, val_nitid_files, val_noisy, val_nitid = dsutils.readDataset( IMG_PATH_VALID, hyperparams.IMG_WIDTH, hyperparams.IMG_HEIGHT, radiance_limits)\n",
    "\n",
    "train_noisy, train_nitid = dsutils.reshapeDataset( train_noisy, train_nitid, hyperparams.IMG_WIDTH, hyperparams.IMG_HEIGHT )\n",
    "val_noisy, val_nitid = dsutils.reshapeDataset( val_noisy, val_nitid, hyperparams.IMG_WIDTH, hyperparams.IMG_HEIGHT )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88b591f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "606/606 [==============================] - 27s 35ms/step - loss: 0.1535 - mean_absolute_error: 0.1535 - val_loss: 0.1553 - val_mean_absolute_error: 0.1553\n",
      "Epoch 2/600\n",
      "606/606 [==============================] - 20s 34ms/step - loss: 0.1440 - mean_absolute_error: 0.1440 - val_loss: 0.1553 - val_mean_absolute_error: 0.1553\n",
      "Epoch 3/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.1440 - mean_absolute_error: 0.1440 - val_loss: 0.1553 - val_mean_absolute_error: 0.1553\n",
      "Epoch 4/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.1440 - mean_absolute_error: 0.1440 - val_loss: 0.1553 - val_mean_absolute_error: 0.1553\n",
      "Epoch 5/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.1440 - mean_absolute_error: 0.1440 - val_loss: 0.1553 - val_mean_absolute_error: 0.1553\n",
      "Epoch 6/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0468 - mean_absolute_error: 0.0468 - val_loss: 0.0230 - val_mean_absolute_error: 0.0230\n",
      "Epoch 7/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0242 - mean_absolute_error: 0.0242 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 8/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0233 - mean_absolute_error: 0.0233 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 9/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0228 - mean_absolute_error: 0.0228 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 10/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0224 - mean_absolute_error: 0.0224 - val_loss: 0.0223 - val_mean_absolute_error: 0.0223\n",
      "Epoch 11/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0221 - mean_absolute_error: 0.0221 - val_loss: 0.0220 - val_mean_absolute_error: 0.0220\n",
      "Epoch 12/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0218 - mean_absolute_error: 0.0218 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 13/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0216 - mean_absolute_error: 0.0216 - val_loss: 0.0226 - val_mean_absolute_error: 0.0226\n",
      "Epoch 14/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0215 - mean_absolute_error: 0.0215 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 15/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0213 - mean_absolute_error: 0.0213 - val_loss: 0.0203 - val_mean_absolute_error: 0.0203\n",
      "Epoch 16/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0211 - mean_absolute_error: 0.0211 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 17/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0210 - mean_absolute_error: 0.0210 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 18/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0209 - mean_absolute_error: 0.0209 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 19/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0207 - mean_absolute_error: 0.0207 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 20/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0206 - mean_absolute_error: 0.0206 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 21/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0205 - mean_absolute_error: 0.0205 - val_loss: 0.0198 - val_mean_absolute_error: 0.0198\n",
      "Epoch 22/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0205 - mean_absolute_error: 0.0205 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 23/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0203 - mean_absolute_error: 0.0203 - val_loss: 0.0206 - val_mean_absolute_error: 0.0206\n",
      "Epoch 24/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0202 - mean_absolute_error: 0.0202 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 25/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0201 - mean_absolute_error: 0.0201 - val_loss: 0.0206 - val_mean_absolute_error: 0.0206\n",
      "Epoch 26/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0199 - mean_absolute_error: 0.0199 - val_loss: 0.0201 - val_mean_absolute_error: 0.0201\n",
      "Epoch 27/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0199 - mean_absolute_error: 0.0199 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 28/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0199 - mean_absolute_error: 0.0199 - val_loss: 0.0204 - val_mean_absolute_error: 0.0204\n",
      "Epoch 29/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0197 - mean_absolute_error: 0.0197 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 30/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0196 - mean_absolute_error: 0.0196 - val_loss: 0.0200 - val_mean_absolute_error: 0.0200\n",
      "Epoch 31/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0197 - mean_absolute_error: 0.0197 - val_loss: 0.0196 - val_mean_absolute_error: 0.0196\n",
      "Epoch 32/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0195 - mean_absolute_error: 0.0195 - val_loss: 0.0200 - val_mean_absolute_error: 0.0200\n",
      "Epoch 33/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0194 - mean_absolute_error: 0.0194 - val_loss: 0.0195 - val_mean_absolute_error: 0.0195\n",
      "Epoch 34/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0194 - mean_absolute_error: 0.0194 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 35/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0194 - mean_absolute_error: 0.0194 - val_loss: 0.0195 - val_mean_absolute_error: 0.0195\n",
      "Epoch 36/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0193 - mean_absolute_error: 0.0193 - val_loss: 0.0196 - val_mean_absolute_error: 0.0196\n",
      "Epoch 37/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0191 - mean_absolute_error: 0.0191 - val_loss: 0.0198 - val_mean_absolute_error: 0.0198\n",
      "Epoch 38/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0191 - mean_absolute_error: 0.0191 - val_loss: 0.0195 - val_mean_absolute_error: 0.0195\n",
      "Epoch 39/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0191 - mean_absolute_error: 0.0191 - val_loss: 0.0236 - val_mean_absolute_error: 0.0236\n",
      "Epoch 40/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0191 - mean_absolute_error: 0.0191 - val_loss: 0.0201 - val_mean_absolute_error: 0.0201\n",
      "Epoch 41/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0189 - mean_absolute_error: 0.0189 - val_loss: 0.0201 - val_mean_absolute_error: 0.0201\n",
      "Epoch 42/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0188 - mean_absolute_error: 0.0188 - val_loss: 0.0211 - val_mean_absolute_error: 0.0211\n",
      "Epoch 43/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0189 - mean_absolute_error: 0.0189 - val_loss: 0.0201 - val_mean_absolute_error: 0.0201\n",
      "Epoch 44/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0188 - mean_absolute_error: 0.0188 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 45/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0188 - mean_absolute_error: 0.0188 - val_loss: 0.0206 - val_mean_absolute_error: 0.0206\n",
      "Epoch 46/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0187 - mean_absolute_error: 0.0187 - val_loss: 0.0205 - val_mean_absolute_error: 0.0205\n",
      "Epoch 47/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0187 - mean_absolute_error: 0.0187 - val_loss: 0.0204 - val_mean_absolute_error: 0.0204\n",
      "Epoch 48/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0186 - mean_absolute_error: 0.0186 - val_loss: 0.0232 - val_mean_absolute_error: 0.0232\n",
      "Epoch 49/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0185 - mean_absolute_error: 0.0185 - val_loss: 0.0196 - val_mean_absolute_error: 0.0196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0185 - mean_absolute_error: 0.0185 - val_loss: 0.0198 - val_mean_absolute_error: 0.0198\n",
      "Epoch 51/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0185 - mean_absolute_error: 0.0185 - val_loss: 0.0196 - val_mean_absolute_error: 0.0196\n",
      "Epoch 52/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0184 - mean_absolute_error: 0.0184 - val_loss: 0.0198 - val_mean_absolute_error: 0.0198\n",
      "Epoch 53/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0184 - mean_absolute_error: 0.0184 - val_loss: 0.0196 - val_mean_absolute_error: 0.0196\n",
      "Epoch 54/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0184 - mean_absolute_error: 0.0184 - val_loss: 0.0205 - val_mean_absolute_error: 0.0205\n",
      "Epoch 55/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0183 - mean_absolute_error: 0.0183 - val_loss: 0.0196 - val_mean_absolute_error: 0.0196\n",
      "Epoch 56/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0183 - mean_absolute_error: 0.0183 - val_loss: 0.0190 - val_mean_absolute_error: 0.0190\n",
      "Epoch 57/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0182 - mean_absolute_error: 0.0182 - val_loss: 0.0196 - val_mean_absolute_error: 0.0196\n",
      "Epoch 58/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0182 - mean_absolute_error: 0.0182 - val_loss: 0.0195 - val_mean_absolute_error: 0.0195\n",
      "Epoch 59/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0181 - mean_absolute_error: 0.0181 - val_loss: 0.0196 - val_mean_absolute_error: 0.0196\n",
      "Epoch 60/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0181 - mean_absolute_error: 0.0181 - val_loss: 0.0205 - val_mean_absolute_error: 0.0205\n",
      "Epoch 61/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0181 - mean_absolute_error: 0.0181 - val_loss: 0.0200 - val_mean_absolute_error: 0.0200\n",
      "Epoch 62/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0180 - mean_absolute_error: 0.0180 - val_loss: 0.0199 - val_mean_absolute_error: 0.0199\n",
      "Epoch 63/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0179 - mean_absolute_error: 0.0179 - val_loss: 0.0195 - val_mean_absolute_error: 0.0195\n",
      "Epoch 64/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0180 - mean_absolute_error: 0.0180 - val_loss: 0.0201 - val_mean_absolute_error: 0.0201\n",
      "Epoch 65/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0178 - mean_absolute_error: 0.0178 - val_loss: 0.0227 - val_mean_absolute_error: 0.0227\n",
      "Epoch 66/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0180 - mean_absolute_error: 0.0180 - val_loss: 0.0193 - val_mean_absolute_error: 0.0193\n",
      "Epoch 67/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0179 - mean_absolute_error: 0.0179 - val_loss: 0.0195 - val_mean_absolute_error: 0.0195\n",
      "Epoch 68/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0179 - mean_absolute_error: 0.0179 - val_loss: 0.0206 - val_mean_absolute_error: 0.0206\n",
      "Epoch 69/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0177 - mean_absolute_error: 0.0177 - val_loss: 0.0197 - val_mean_absolute_error: 0.0197\n",
      "Epoch 70/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0177 - mean_absolute_error: 0.0177 - val_loss: 0.0188 - val_mean_absolute_error: 0.0188\n",
      "Epoch 71/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0177 - mean_absolute_error: 0.0177 - val_loss: 0.0191 - val_mean_absolute_error: 0.0191\n",
      "Epoch 72/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0178 - mean_absolute_error: 0.0178 - val_loss: 0.0194 - val_mean_absolute_error: 0.0194\n",
      "Epoch 73/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0175 - mean_absolute_error: 0.0175 - val_loss: 0.0204 - val_mean_absolute_error: 0.0204\n",
      "Epoch 74/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0176 - mean_absolute_error: 0.0176 - val_loss: 0.0206 - val_mean_absolute_error: 0.0206\n",
      "Epoch 75/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0176 - mean_absolute_error: 0.0176 - val_loss: 0.0205 - val_mean_absolute_error: 0.0205\n",
      "Epoch 76/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0174 - mean_absolute_error: 0.0174 - val_loss: 0.0215 - val_mean_absolute_error: 0.0215\n",
      "Epoch 77/600\n",
      "606/606 [==============================] - 20s 34ms/step - loss: 0.0175 - mean_absolute_error: 0.0175 - val_loss: 0.0205 - val_mean_absolute_error: 0.0205\n",
      "Epoch 78/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0174 - mean_absolute_error: 0.0174 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 79/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0174 - mean_absolute_error: 0.0174 - val_loss: 0.0201 - val_mean_absolute_error: 0.0201\n",
      "Epoch 80/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0174 - mean_absolute_error: 0.0174 - val_loss: 0.0202 - val_mean_absolute_error: 0.0202\n",
      "Epoch 81/600\n",
      "606/606 [==============================] - 21s 34ms/step - loss: 0.0173 - mean_absolute_error: 0.0173 - val_loss: 0.0218 - val_mean_absolute_error: 0.0218\n",
      "Epoch 82/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0174 - mean_absolute_error: 0.0174 - val_loss: 0.0197 - val_mean_absolute_error: 0.0197\n",
      "Epoch 83/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0173 - mean_absolute_error: 0.0173 - val_loss: 0.0204 - val_mean_absolute_error: 0.0204\n",
      "Epoch 84/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0172 - mean_absolute_error: 0.0172 - val_loss: 0.0229 - val_mean_absolute_error: 0.0229\n",
      "Epoch 85/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0173 - mean_absolute_error: 0.0173 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 86/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0171 - mean_absolute_error: 0.0171 - val_loss: 0.0201 - val_mean_absolute_error: 0.0201\n",
      "Epoch 87/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0171 - mean_absolute_error: 0.0171 - val_loss: 0.0209 - val_mean_absolute_error: 0.0209\n",
      "Epoch 88/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0170 - mean_absolute_error: 0.0170 - val_loss: 0.0199 - val_mean_absolute_error: 0.0199\n",
      "Epoch 89/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0170 - mean_absolute_error: 0.0170 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 90/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0170 - mean_absolute_error: 0.0170 - val_loss: 0.0212 - val_mean_absolute_error: 0.0212\n",
      "Epoch 91/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0169 - mean_absolute_error: 0.0169 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 92/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0170 - mean_absolute_error: 0.0170 - val_loss: 0.0201 - val_mean_absolute_error: 0.0201\n",
      "Epoch 93/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0169 - mean_absolute_error: 0.0169 - val_loss: 0.0196 - val_mean_absolute_error: 0.0196\n",
      "Epoch 94/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0170 - mean_absolute_error: 0.0170 - val_loss: 0.0225 - val_mean_absolute_error: 0.0225\n",
      "Epoch 95/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0169 - mean_absolute_error: 0.0169 - val_loss: 0.0206 - val_mean_absolute_error: 0.0206\n",
      "Epoch 96/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0169 - mean_absolute_error: 0.0169 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 97/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0168 - mean_absolute_error: 0.0168 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 98/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0169 - mean_absolute_error: 0.0169 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0168 - mean_absolute_error: 0.0168 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 100/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0167 - mean_absolute_error: 0.0167 - val_loss: 0.0207 - val_mean_absolute_error: 0.0207\n",
      "Epoch 101/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0166 - mean_absolute_error: 0.0166 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 102/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0166 - mean_absolute_error: 0.0166 - val_loss: 0.0204 - val_mean_absolute_error: 0.0204\n",
      "Epoch 103/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0166 - mean_absolute_error: 0.0166 - val_loss: 0.0199 - val_mean_absolute_error: 0.0199\n",
      "Epoch 104/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0166 - mean_absolute_error: 0.0166 - val_loss: 0.0193 - val_mean_absolute_error: 0.0193\n",
      "Epoch 105/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0166 - mean_absolute_error: 0.0166 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 106/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0164 - mean_absolute_error: 0.0164 - val_loss: 0.0202 - val_mean_absolute_error: 0.0202\n",
      "Epoch 107/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0164 - mean_absolute_error: 0.0164 - val_loss: 0.0217 - val_mean_absolute_error: 0.0217\n",
      "Epoch 108/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0164 - mean_absolute_error: 0.0164 - val_loss: 0.0198 - val_mean_absolute_error: 0.0198\n",
      "Epoch 109/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0164 - mean_absolute_error: 0.0164 - val_loss: 0.0216 - val_mean_absolute_error: 0.0216\n",
      "Epoch 110/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0164 - mean_absolute_error: 0.0164 - val_loss: 0.0204 - val_mean_absolute_error: 0.0204\n",
      "Epoch 111/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0164 - mean_absolute_error: 0.0164 - val_loss: 0.0203 - val_mean_absolute_error: 0.0203\n",
      "Epoch 112/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0164 - mean_absolute_error: 0.0164 - val_loss: 0.0196 - val_mean_absolute_error: 0.0196\n",
      "Epoch 113/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0163 - mean_absolute_error: 0.0163 - val_loss: 0.0213 - val_mean_absolute_error: 0.0213\n",
      "Epoch 114/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0163 - mean_absolute_error: 0.0163 - val_loss: 0.0210 - val_mean_absolute_error: 0.0210\n",
      "Epoch 115/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0162 - mean_absolute_error: 0.0162 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 116/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0163 - mean_absolute_error: 0.0163 - val_loss: 0.0214 - val_mean_absolute_error: 0.0214\n",
      "Epoch 117/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0162 - mean_absolute_error: 0.0162 - val_loss: 0.0208 - val_mean_absolute_error: 0.0208\n",
      "Epoch 118/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0161 - mean_absolute_error: 0.0161 - val_loss: 0.0203 - val_mean_absolute_error: 0.0203\n",
      "Epoch 119/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0162 - mean_absolute_error: 0.0162 - val_loss: 0.0201 - val_mean_absolute_error: 0.0201\n",
      "Epoch 120/600\n",
      "606/606 [==============================] - 21s 35ms/step - loss: 0.0162 - mean_absolute_error: 0.0162 - val_loss: 0.0198 - val_mean_absolute_error: 0.0198\n",
      "Train size:9696\n",
      "Valid.size:2368\n",
      "--- 2502.7007830142975 seconds ---\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# TRAIN MODEL\n",
    "##################\n",
    "#import tensorflow as tf\n",
    "#from tensorflow.compat.v1.keras.backend import set_session\n",
    "#config = tf.compat.v1.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "#config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "#sess = tf.compat.v1.Session(config=config)\n",
    "#set_session(sess)\n",
    "\n",
    "\n",
    "hist = train.fit( model, hyperparams, train_noisy, train_nitid, val_noisy, val_nitid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8148067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAx80lEQVR4nO3deZxcVZ338c+vblXv2RMgJEDCGgOyGQKCOsiiYZGggEaBUccRUVFgXFh8fHRmnBnnGccRRyQgiwsIKoJGiSCiuBEgCXsSImEJ6SykydZLeqnl9/xxbneKppJUVbrodPX3/Xr1q6vuVudUd93vPefce8vcHRERkf4Sg10AERHZPSkgRESkIAWEiIgUpIAQEZGCFBAiIlKQAkJERApSQIgMADP7vpl9rchlXzKzU3Z1OyKVpoAQEZGCFBAiIlKQAkKGjbhr5wtm9pSZdZjZTWa2p5n9xszazOx3ZjYmb/mzzGyJmW02swfN7E15844ys8fi9X4C1PV7rTPN7Il43YfM7PAyy/xxM1thZhvNbJ6Z7R1PNzP7HzNbb2Zb4jodFs873cyWxmVbbWafL+sNk2FPASHDzTnAqcDBwHuA3wBXA+MJn4fPApjZwcDtwGXABGA+8CszqzGzGuAXwI+AscDP4u0Sr3s0cDPwCWAccD0wz8xqSymomZ0E/AfwfmAisBK4I579LuAdcT1GAx8ANsTzbgI+4e4jgMOA35fyuiK9FBAy3Pyvu7/i7quBPwOPuPvj7t4N3A0cFS/3AeAed7/f3dPAN4B64HjgOCAFfMvd0+5+J7Aw7zU+Dlzv7o+4e9bdfwB0x+uV4nzgZnd/LC7fVcBbzWwKkAZGANMAc/dl7r42Xi8NTDezke6+yd0fK/F1RQAFhAw/r+Q97izwvCl+vDfhiB0Ad88Bq4BJ8bzV/to7Xa7Me7wf8Lm4e2mzmW0G9onXK0X/MrQTWgmT3P33wHeAa4FXzOwGMxsZL3oOcDqw0sz+aGZvLfF1RQAFhMj2rCHs6IHQ50/Yya8G1gKT4mm99s17vAr4N3cfnffT4O6372IZGgldVqsB3P3b7v4W4FBCV9MX4ukL3X02sAehK+ynJb6uCKCAENmenwJnmNnJZpYCPkfoJnoIWABkgM+aWdLM3gfMzFv3e8DFZnZsPJjcaGZnmNmIEsvwY+CjZnZkPH7x74QusZfM7Jh4+ymgA+gCsvEYyflmNiruGmsFsrvwPsgwpoAQKcDdlwMXAP8LvEoY0H6Pu/e4ew/wPuAjwCbCeMVdeesuIoxDfCeevyJettQyPAB8Gfg5odVyADAnnj2SEESbCN1QGwjjJAAXAi+ZWStwcVwPkZKZvjBIREQKUQtCREQKUkCIiEhBCggRESlIASEiIgUlK7lxM5sFXANEwI3u/vV+86cBtwBHA19y92/kzRsN3Ei4VYAD/+DuC3b0euPHj/cpU6YMZBVERKra4sWLX3X3CYXmVSwgzCwiXOV5KtAMLDSzee6+NG+xjYR735xdYBPXAPe6+7nxvW8advaaU6ZMYdGiRbtcdhGR4cLMVm5vXiW7mGYCK9z9hfi88TuA2fkLuPt6d19IuHdMn/iWAe8g3HSM+NzzzRUsq4iI9FPJgJhEuOVAr+Z4WjH2B1qAW8zscTO7Mb7NgIiIvEEqGRBWYFqxV+UlCeMS17n7UYRbCVxZ8EXMLjKzRWa2qKWlpbySiojI61RykLqZcHOzXpMJNx8rdt1md38kfn4n2wkId78BuAFgxowZrwugdDpNc3MzXV1dxZZ7SKqrq2Py5MmkUqnBLoqIVIlKBsRC4CAzm0q4++Qc4EPFrOju68xslZkdEt8T52Rg6c7WK6S5uZkRI0YwZcoUXnvzzerh7mzYsIHm5mamTp062MURkSpRsYBw94yZXQLcRzjN9WZ3X2JmF8fz55rZXsAiwo3HcmZ2GTDd3VuBzwC3xWcwvQB8tJxydHV1VXU4AJgZ48aNQ11sIjKQKnodhLvPJ3xVY/60uXmP1xG6ngqt+wQwYyDKUc3h0Gs41FFE3lgVDYgho20d7Oyutr074NoRUKMTqkSk+ulWGwDtr0D7uh3/tK0NP62rS9r05s2b+e53v1tykU4//XQ2b95c8noiIgNFLQiAiUfg7tvvpultXWx8HnKlfTlXb0B86lOfes30bDZLFEXbXW/+/PnbnSci8kYY9gGRc+e5V9oZ05Bij5F1hRfqCw6j+Es5giuvvJLnn3+eI488klQqRVNTExMnTuSJJ55g6dKlnH322axatYquri4uvfRSLrroImDbbUPa29s57bTTeNvb3sZDDz3EpEmT+OUvf0l9fX35lRYRKcKwCoh//tUSlq5pfd30zp4siQTUJrd/RA9Apgs8B6lNfZOm7z2Sr7zn0O2u8vWvf51nnnmGJ554ggcffJAzzjiDZ555pu901JtvvpmxY8fS2dnJMcccwznnnMO4ceNes43nnnuO22+/ne9973u8//3v5+c//zkXXKBvkRSRyhpWAbE9iQRkc2/Ma82cOfM11yp8+9vf5u677wZg1apVPPfcc68LiKlTp3LkkUcC8Ja3vIWXXnrpjSmsiAxrwyogtnekv761i3WtXUzfeyTJxA7G7Te+COlO2HN62WVobNx2BtSDDz7I7373OxYsWEBDQwMnnnhiwSu+a2tr+x5HUURnZ2fZry8iUiydxQTU14Supa70TpoRZVxrMGLECNra2grO27JlC2PGjKGhoYFnn32Whx9+uOTti4hUyrBqQWxPXSoERGdPlqbaHb0lpQ9Sjxs3jhNOOIHDDjuM+vp69txzz755s2bNYu7cuRx++OEccsghHHfccWWUXkSkMhQQQCpKkIwSdKWLOIV1ZxfUFfDjH/+44PTa2lp+85vfFJzXO84wfvx4nnnmmb7pn//850t+fRGRcqiLKVafiujcWUDodhYiMowoIGL1qQTd6Ry5HbYQSu9iEhEZqhQQsbpUhON076gVYZTVxSQiMhQpIGL1vQPVOzyTSV1MIjJ8KCBiNckECbOdjEOoi0lEhg8FRMzMqE9FdPWoi0lEBHSa62vU1URs6uhhQ3t3wfkN6Rx1VLajqampifb29gq+gohIcRQQeRprIja0O6s3F76VxZ6Woc7UghCR4UEBkWd0Qw1NtcntjjK0tbRiOUI3U5HXRFxxxRXst99+fd8H8dWvfhUz409/+hObNm0inU7zta99jdmzZw9MJUREBsjwCojfXAnrnt7hIjt6Q0aku8DTUNNEX0fTXm+G076+3XXmzJnDZZdd1hcQP/3pT7n33nu5/PLLGTlyJK+++irHHXccZ511lr5XWkR2KxUdpDazWWa23MxWmNmVBeZPM7MFZtZtZq+7h4SZRWb2uJn9upLlrKSjjjqK9evXs2bNGp588knGjBnDxIkTufrqqzn88MM55ZRTWL16Na+88spgF1VE5DUq1oIwswi4FjgVaAYWmtk8d1+at9hG4LPA2dvZzKXAMmDkgBRqB0f6xWhf38yYTAvsdTgkdvLlQnnOPfdc7rzzTtatW8ecOXO47bbbaGlpYfHixaRSKaZMmVLwNt8iIoOpki2ImcAKd3/B3XuAO4DXdLS7+3p3Xwik+69sZpOBM4AbK1jGEvV2AZU2UD1nzhzuuOMO7rzzTs4991y2bNnCHnvsQSqV4g9/+AMrV64c+KKKiOyiSgbEJGBV3vPmeFqxvgV8EdjhlzSY2UVmtsjMFrW0tJRcyJKUlw8ceuihtLW1MWnSJCZOnMj555/PokWLmDFjBrfddhvTpk0b8KKKiOyqSg5SFxpxLWrXamZnAuvdfbGZnbijZd39BuAGgBkzZlT4HNQyEwJ4+ultg+Pjx49nwYIFBZfTNRAisruoZAuiGdgn7/lkYE2R654AnGVmLxG6pk4ys1sHtnils10ICBGRoaaSAbEQOMjMpppZDTAHmFfMiu5+lbtPdvcp8Xq/d/cLKlfUIikfRGQYqVgXk7tnzOwS4D4gAm529yVmdnE8f66Z7QUsIpyllDOzy4Dp7t46wGUZoGsMdt+EcN0jSkQGWEUvlHP3+cD8ftPm5j1eR+h62tE2HgQeLLcMdXV1bNiwgXHjxu16SNjuGRDuzoYNG6irqxvsoohIFan6K6knT55Mc3MzA3GGU2dHG/XpTbAxgig1AKUbOHV1dUyevMOsFREpSdUHRCqVYurUqQOyrd/ccR2nPXslmU/8leTENw3INkVEdlf6PogSWBTyNJvd0ZcKiYhUBwVECSy+vUYm0zPIJRERqTwFRAkSvS2IjFoQIlL9FBAl6Otiyrzu1lEiIlVHAVGCqG8MIjPIJRERqTwFRAl6xyByGqQWkWFAAVGCRDJc+5DVILWIDAMKiBIkIrUgRGT4UECUIBFfPa0xCBEZDhQQJegdpM4pIERkGFBAlGDbdRAKCBGpfgqIEkTJuAWRU0CISPVTQJQgiscgXBfKicgwoIAoQZQMZzFlczqLSUSqnwKiBL1nMbkGqUVkGFBAlEBjECIynCggSpBM9o5BKCBEpPpVNCDMbJaZLTezFWZ2ZYH508xsgZl1m9nn86bvY2Z/MLNlZrbEzC6tZDmL1XcdhMYgRGQYqNhXjppZBFwLnAo0AwvNbJ67L81bbCPwWeDsfqtngM+5+2NmNgJYbGb391v3DdfXgtAYhIgMA5VsQcwEVrj7C+7eA9wBzM5fwN3Xu/tCIN1v+lp3fyx+3AYsAyZVsKxF6R2DcI1BiMgwUMmAmASsynveTBk7eTObAhwFPLKd+ReZ2SIzW9TS0lJOOYumgBCR4aSSAWEFpnlJGzBrAn4OXOburYWWcfcb3H2Gu8+YMGFCGcUs3rYuJo1BiEj1q2RANAP75D2fDKwpdmUzSxHC4TZ3v2uAy1aWZCoOCLUgRGQYqGRALAQOMrOpZlYDzAHmFbOimRlwE7DM3b9ZwTKWJNV7oZzOYhKRYaBiZzG5e8bMLgHuAyLgZndfYmYXx/PnmtlewCJgJJAzs8uA6cDhwIXA02b2RLzJq919fqXKW4woSpBzA7UgRGQYqFhAAMQ79Pn9ps3Ne7yO0PXU318oPIYxqFKRkSahFoSIDAu6kroEZkaOhFoQIjIsKCBKlCVSC0JEhgUFRImyJEABISLDgAKiRFmL1MUkIsOCAqJEORKYqwUhItVPAVGiLJG6mERkWFBAlEhnMYnIcKGAKFHOIvDcYBdDRKTiFBAlylkCUwtCRIYBBUSJcqgFISLDgwKiRG4JzNWCEJHqp4AoUY6kTnMVkWFBAVGi0IJQF5OIVD8FRIlyFmG6DkJEhgEFRIncInUxiciwoIAoUU4BISLDhAKiRG4JEmgMQkSqnwKiRG5JEjrNVUSGAQVEiXQWk4gMFwqIEnkiSUJjECIyDFQ0IMxslpktN7MVZnZlgfnTzGyBmXWb2edLWXfQaAxCRIaJigWEmUXAtcBpwHTgg2Y2vd9iG4HPAt8oY91BEcYg1IIQkepXyRbETGCFu7/g7j3AHcDs/AXcfb27LwTSpa47aBIRhgJCRKpfJQNiErAq73lzPG1A1zWzi8xskZktamlpKaugpXCLiDRILSLDQCUDwgpM84Fe191vcPcZ7j5jwoQJRReuXJaISKgFISLDQCUDohnYJ+/5ZGDNG7BuRXkiItIgtYgMA5UMiIXAQWY21cxqgDnAvDdg3cqyJAlyuBfbGBIRGZqSldqwu2fM7BLgPiACbnb3JWZ2cTx/rpntBSwCRgI5M7sMmO7urYXWrVRZS2GJBEmyZHJOKirUEyYiUh0qFhAA7j4fmN9v2ty8x+sI3UdFrbtbSIQWRDbnpKLBLoyISOXoSupSJSKSZElnNQ4hItVNAVGqRJIETiarMQgRqW4KiBJZbwsipxaEiFQ3BUSJLG8MQkSkmikgShW3INTFJCLVTgFRokSUJDInndHV1CJS3RQQJbJEOLc1k9W3yolIdVNAlMiiFADZjAJCRKpbUQFhZpea2UgLbjKzx8zsXZUu3O6orwWR6X+HchGR6lJsC+If3L0VeBcwAfgo8PWKlWo3ZlG4+DyjFoSIVLliA6L3pkOnA7e4+5MUviV31UtEoQWRVQtCRKpcsQGx2Mx+SwiI+8xsBAzPe14nEqEFkdMgtYhUuWJv1vcx4EjgBXffamZjCd1Mw05vF1NWASEiVa7YFsRbgeXuvtnMLgD+D7ClcsXafSV6A0JjECJS5YoNiOuArWZ2BPBFYCXww4qVaje2LSA0BiEi1a3YgMh4+Aq12cA17n4NMKJyxdp99QZELqsrqUWkuhU7BtFmZlcBFwJvN7MISFWuWLuvvhZETl1MIlLdim1BfADoJlwPsQ6YBPxXxUq1G4v6rqRWF5OIVLeiAiIOhduAUWZ2JtDl7sN0DCJcB5HTILWIVLlib7XxfuBR4Dzg/cAjZnZuEevNMrPlZrbCzK4sMN/M7Nvx/KfM7Oi8eZeb2RIze8bMbjezuuKrVTmJZDwGoS4mEalyxY5BfAk4xt3XA5jZBOB3wJ3bWyEep7gWOBVoBhaa2Tx3X5q32GnAQfHPsYSzpY41s0nAZ4Hp7t5pZj8F5gDfL6FuFdHbxaQWhIhUu2LHIBK94RDbUMS6M4EV7v6Cu/cAdxDOgso3G/ihBw8Do81sYjwvCdSbWRJoANYUWdaKUgtCRIaLYgPiXjO7z8w+YmYfAe4B5u9knUnAqrznzfG0nS7j7quBbwAvA2uBLe7+20IvYmYXmdkiM1vU0tJSZHXKl9RpriIyTBQ7SP0F4AbgcOAI4AZ3v2InqxW6mV//7+ksuIyZjSG0LqYCewON8RXchcp2g7vPcPcZEyZM2EmRdl0i7mLyrM5iEpHqVuwYBO7+c+DnJWy7Gdgn7/lkXt9NtL1lTgFedPcWADO7CzgeuLWE16+IZDI+i0ktCBGpcjtsQZhZm5m1FvhpM7PWnWx7IXCQmU01sxrCIPO8fsvMA/4+PpvpOEJX0lpC19JxZtZgZgacDCwrq4YDzBJxCyKnFoSIVLcdtiDcvezbabh7xswuAe4DIuBmd19iZhfH8+cSxjFOB1YAW4nvEOvuj5jZncBjQAZ4nNDFNfgSakGIyPBQdBdTOdx9Pv0Gs+Ng6H3swKe3s+5XgK9UsnxlsdDocp3FJCJVrtizmKRX/IVBrhaEiFQ5BUSp4i4mtSBEpNopIErV24JQQIhIlVNAlMp6WxDqYhKR6qaAKFVvF5PGIESkyikgShUHBOpiEpEqp4AoVd8YhFoQIlLdFBClMrUgRGR4UECUSi0IERkmFBClSoS3zNSCEJEqp4AoVW8LwtWCEJHqpoAoVTwGYepiEpEqp4AoVdyCQAEhIlVOAVGq3usgXGMQIlLdFBClim/3TS43uOUQEakwBUSpzMiSIKEWhIhUOQVEGXKWBJ3FJCJVTgFRBiehs5hEpOopIMqQswhTC0JEqlxFA8LMZpnZcjNbYWZXFphvZvbteP5TZnZ03rzRZnanmT1rZsvM7K2VLGspcpZQQIhI1atYQJhZBFwLnAZMBz5oZtP7LXYacFD8cxFwXd68a4B73X0acASwrFJlLZVbEnOdxSQi1a2SLYiZwAp3f8Hde4A7gNn9lpkN/NCDh4HRZjbRzEYC7wBuAnD3HnffXMGylsQtgeksJhGpcpUMiEnAqrznzfG0YpbZH2gBbjGzx83sRjNrrGBZS5KziIRaECJS5SoZEFZgmhe5TBI4GrjO3Y8COoDXjWEAmNlFZrbIzBa1tLTsSnmL5hZh5HDvXx0RkepRyYBoBvbJez4ZWFPkMs1As7s/Ek+/kxAYr+PuN7j7DHefMWHChAEp+M64RURkyeQUECJSvSoZEAuBg8xsqpnVAHOAef2WmQf8fXw203HAFndf6+7rgFVmdki83MnA0gqWtTQWEZEjk1VAiEj1SlZqw+6eMbNLgPuACLjZ3ZeY2cXx/LnAfOB0YAWwFfho3iY+A9wWh8sL/eYNKk/0tiByhKqJiFSfigUEgLvPJ4RA/rS5eY8d+PR21n0CmFHJ8pUrdDG5WhAiUtV0JXU54jGItO7oKiJVTAFRhtDFpDEIEaluCohyWESSLFmdxSQiVUwBUY5EkgQ50ll1MYlI9VJAlCORIGk5XQchIlVNAVEOUwtCRKqfAqIcCY1BiEj1U0CUo28MQgEhItVLAVEGS0QkyZFRF5OIVDEFRDkSyXAdhLqYRKSKKSDKYImE7uYqIlVPAVGORCq+klpdTCJSvRQQZbAo3GpDg9QiUs0UEGVIRGEMojuTHeyiiIhUjAKiDDWpFJFl2bw1PdhFERGpGAVEGWpSNUTk2NDRM9hFERGpGAVEGRJRRMpybFJAiEgVU0CUI5EkwtmogBCRKqaAKIdFJC2rgBCRqqaAKEf8jXKbtiogRKR6VTQgzGyWmS03sxVmdmWB+WZm347nP2VmR/ebH5nZ42b260qWs2RxQGiQWkSqWcUCwswi4FrgNGA68EEzm95vsdOAg+Kfi4Dr+s2/FFhWqTKWLZEkQZZNHT2462I5EalOlWxBzARWuPsL7t4D3AHM7rfMbOCHHjwMjDaziQBmNhk4A7ixgmUsj0VEHu7F1NadGezSiIhURCUDYhKwKu95czyt2GW+BXwR2OENj8zsIjNbZGaLWlpadqnARUskw2uTY2O7uplEpDpVMiCswLT+/TEFlzGzM4H17r54Zy/i7je4+wx3nzFhwoRyylm6RHjbkuTYqIFqEalSlQyIZmCfvOeTgTVFLnMCcJaZvUTomjrJzG6tXFFLFLcgEuhiORGpXpUMiIXAQWY21cxqgDnAvH7LzAP+Pj6b6Thgi7uvdfer3H2yu0+J1/u9u19QwbKWxiIAkmR1JpOIVK1kpTbs7hkzuwS4D4iAm919iZldHM+fC8wHTgdWAFuBj1aqPAMqbkFEakGISBWrWEAAuPt8QgjkT5ub99iBT+9kGw8CD1ageOVLhBZEXRJdTS0iVUtXUpfDwts2vj5SQIhI1VJAlCPuYhrbEOl2GyJStRQQ5Yi7mMbVRxqkFpGqpYAoR9yCGFMfaZBaRKqWAqIc8WmuY+sTGoMQkaqlgChH3MU0ui6itStDOrvDu4GIiAxJCohyxAExpi481UC1iFQjBUQ54jGIUXXh96aO9GCWRkSkIhQQ5YjHIEbFLYgNHd2DWBgRkcpQQJQjbkGMrg1BoRaEiFQjBUQ54tt9j6gNdyvfqBaEiFQhBUQ54hbEyL6AUAtCRKqPAqIcfbf7zjGyLqmzmESkKikgyhG3IMhlGdtYo9ttiEhVUkCUI74OglyWMY01ut2GiFQlBUQ5egPCs4xrrNHtNkSkKikgymG9LYgM+41rZOnaVj7xo0U83bxlcMs1lK15HNY+NdilEJE8Ff1GuarVNwaR4fJTD6apNsktf32R+5a8wiF7juBtB43nbQeO5+j9xjCqPrXjbbmDWeXLvDvL9MCPPwAYXPoEpOoHdvsP/Gto9b3z6oHdbqV0vAqN4we7FOVb9wxs3QD7/91gl0R2kQKiHCMmQrIOFlxL00Hv5vJTD+Zjb5/KTxeu4sHlLfzo4ZXc9JcXmWgb+OSoBewxohbfYzqNU2awz9RD2HdsA1HC4Mk74J7Pw1s/De/4PEQ7CZNqteRuaH8lPF50c3g/Bsrf7oM/fwMwOOwcmHDIwG27EhZ/H351Gcz5MUw7fbBLU7rWtfCD90DXFjj/Z3DgyZV5na0b4e6L4S0fGZrv0xBh4WuhK7Rxs1nANUAE3OjuX+833+L5pwNbgY+4+2Nmtg/wQ2AvIAfc4O7X7Oz1ZsyY4YsWLRrgWmzHkl/Azz4Mbz4P3ve9ba2AXI7uFxew5S83MO6lX2GeI0F4j3NuXJ89k+/wfuaMeJovdX6D1tR4RqfXs77pTTxyxL9RN+kw9hpZx4QRtYxrqiEVDXIv4CtLQl3f+mmoH13cOisXwKpH4IRLd946cocb/g7SnTBiL3hlKVz6JNQ27Xy95fNhzBTY89DCy3S1wnePg1QDtK4JO5JzbiyuDoNh44tw3QmQ7oAJ0+CTD20b76qUng74272wz7EwanJx6zw7Hx65Dt5zDYzdf9v0XA5ufS+8/AiM3hfa1sE/3l9cKK99MoTLqMlh3bqRO17+l5+Gx2+FRAo+9JPygyjdBeuegolHQLK2tHWzafjzN8N7cPh526Y/fht0boJjL4ZoB8fguSxsXgmj9nn9wWE2Ay8vgJoG2PvoivYymNlid59RaF7FWhBmFgHXAqcCzcBCM5vn7kvzFjsNOCj+ORa4Lv6dAT4Xh8UIYLGZ3d9v3cF16Nmw4cvw+38Fz4V/6p4OWH4vtVteZo+aJjj2E+GnYTwdq5fQ+fDNfPJvd3Be3ZOM6VzNsuQ0LspezVHZxfxL2/eY9ZfzuCl7Gpdl3ksjXcyKHmVaaj2dtePpqZvA6FSGCbaFsdbGCOuiia1Y4zgYewDRxMPgwFOora0hmTCi5fNJLbyOxB7TYP93hm6xv90LKx8K/9BT3w77nwh7Hrbtn6+9BVqehbFToWlP+Ou34MH/hFwanr0HLrgTRu694/dl3TNw27nQ0x52+u+8asfLv/xw2Dmc+T+hLDedCo9eD2//XJify4aW1uLvw5QT4G2Xh+8En/dZWHJXWObAU+CYj4d6NY6HutHhavfffTUEwz/+DpbNg79+G97xRZhwcLl/9crJZeEXnwqB8O5/h/uuhqd+Akd+6LXLpbsgvRUaxpa+/c7N0LU5BGbtCFj2K3jgX6BtDUS1MPPjcNSF0LkxtOj2OhzGHfDa7Sy6Be75p/A//+MPwMfu33bgsOA78MKDITgOOAm+d1JYZs5t20J84wvwzF2w95Hh7wbwyPVw75VhmwAYTD4GDjkt/EyY9tod5It/CuEw42Ow6lG443w47xZonBDql02H+na3wfql4SeRDAcToyaH1n+UguZFsPSX0N0aPr8nfRkOO7fvTgmv0XtAkkiFrrPOzeEA8eUF8d+lI7RmFlwb/nYQtv2+618bor16OuD2D8KLfwzbHHdgKN+IvcCzIYS3vhqWHXdgOBA98JQQZG9gT0PFWhBm9lbgq+7+7vj5VQDu/h95y1wPPOjut8fPlwMnuvvaftv6JfAdd79/R6/5hrYgIPzTzP98+NBYIvzh9n0rHP4BmHZG4aPgv90H8z4T/iEvuKvvSKl7yzpyv/0q9UtuJ51sIpVpD9MT9dTmOvtWz2Fs8SZavZ6t1DHWWtnTNgPwcm4CN2TP5C2Jv/He6K+syk1gbKKNRroA6Ew0sLLxCMb3rGZ898sAtNdPom2fd9LU9jxN6x7B4g+pJ1JYLk1u+ntJHDobfnkJ1I8JraXJx4QjI3fYsAIy3bDHm6B9Pdx4cpi+z0xY+gs45yZ487mvf98gfOh/cmH4wP/TsnC0dNt54UN/3CfDdp+9B15dHj48m16C+rFQNyocefWOKTxyPXS0vPY1kvWQ6YTjPg2z/j3063/rzeHvcs6NIbwy3TtuFa18CP7839C8EI48H47/LIycuKP/iG26WkPQPXpj+NAfcFJ4T2qawg5q3AHbdvLdbeFI9C/fhLOvgyM+CDecGPrxP7M4HNm6hx36vVeGI/M3nwdv/6edH50//wd44J9hzRNAgc/63kfDO74Az/4anrw9byedN/+gU8Prb1kVljnwVJh5EdzxIdjveDj9v8JnYOGNcMgseP+Pwt921UL44Vkh0PZ8MzTtAc//fls5DjgpfA4Wfx8OOQPedhm0rob1y8LnZO0TYbnR+8HBs8IOcvIMuPGUsBP95IJwIHLLaeH/sJCoJrxHDmx6MSzfq6YJ3nRWOPB45PrQkhh3YAilg94F+x4f/s8zPXDP5SGUAGpGQLIm/A+d8U145uew4n449H3hoGX6bJh2Zug+zvaEA66aRhgzNQT+3keF4Gx+FP7uivB/uH4ZbGmGtrWQ6Qqvf+h7Q1fdUz+Bl/4S3reaphASY6eG4Bm7P4w9IPzeWat7O3bUgqhkQJwLzHL3f4yfXwgc6+6X5C3za+Dr7v6X+PkDwBXuvihvmSnAn4DD3L21wOtcBFwEsO+++75l5cqVFanPgMr0xIFSoAG3amFovk94E0w/K/xz92wNR3SpBmgYhyci2rozvNrWzaatPWzZvImaVX9m2nPfY/yWZ8haksf2/QcenfxRXu3ooX7943R0dvFw+kA2dBk9mSxjcxs4NvsYpyYW8fbEM6zyCdyTO5bHcgezj61nqq3j0dwh/NZnMqahhqNTK/mv7n9ljG9mK3U8n9iPKb6GEd4GQHfURCZZT02mnXtm3MLGhv057bFPMKFtCS/v9S7q6aY+20595xpq2tfiqQYyYw8itW4xXcdcQvbkr2BAbu1TNN16GpbpCkd94w+GE68MH+R1T8H9/xdefQ7ee31oBUH4oK56JARU+/qww013hA/y8Z8JwQPw2y/DQ/8bjiK3NAMewmbUvuFD2dESdmZ1o8JOfMsqaBgP+x4Hy38TynPYOSHw9jseXvxzCMEtzeGIvHZEOHpNd8LKv4aj2QNODs+bH4VcJu8PbaHFNGpyOOrOdIYdy3k/CDvX538PP3ovHPEhaJoAqx+Dl/4c1tnv+LCzSneG8pz0pW1HqV1bws5m/dIQrit+F+p3+PvDDrp2ZKhjd2vYYb3prG1HzC3LYfXi0HpsGBde7+mfhRYehNA9Yk4IhCgVulJ++akwL5EKO7TT/184kOjV8WpoMTx1R/jbHHl+2Ek++2v443+G8h73KXjX117fnda6JgTF3+6N36Ou8L7hcOHdIWAAOjbAiw+Gv3fdqBColggnO4yZuu1z5h5eL9sT/k4NY7edEJHLhR39E7fCS38NreaGceH92bAivBfv+AJMngnP/ir8zU/9V9jrsNCqu30OvPCHsPy5N4f3Z0tzCP72V0IwrX0ydD1FtSHgzrkxvGfFaG8J/1Mv/Tm00je9uG3cDkK9r1hZVlfUYAXEecC7+wXETHf/TN4y9wD/0S8gvujui+PnTcAfgX9z97t29ppveAtid+MejnbrRhfVjdKTybFuSxfNG9vozkLOIZtzsjknnXO2dKZpaetmQ3s37d0Zch0bOLTzMaann2Zyzwu8ZJNZmDmAjV1wRG4ZhyZe4n8y5/Jg7kgAxtDK3JpvsTcb2Eot7dSz2sezxsczgq0cmFjNSLby4Z4rWM+2nUpElihKMGFEA+OaamisSdJQE9GVydLelaEnk6OxNhn/RNSlIhpqoni5JDXJBAmDKGHU14R5dcmIxuxmDl14NbmaEfSM2h9P1lHTvoqa9jUkahpIjNiDVF0jUXcriZ5W2Pc47OgLsZrGMD7w12vCTqS7NeyAPAe1o0KId7eFnUBUE4J83P6hO2zvo0KlulrDDjgTdxGtfSp82De9FI4W33xu2Pn07qzd4dZz4PkHwg5l5N6hu/KYj4cdXseG0KXz8HVhZ7b/O2Hj86ELp1f92FCGmRdBqq78/6tMT9jhFdr5LLwptHSO/vvQUirF1o2hS3O/43e+bLoLXn4IVjwQXuf4z+x8nXJ1t4WW15K7Qzhl0zD7OyEct1u+zlC2g9+9/S6gdFcIxiV3w9EfhoPftYvlbA9/740vhDIffWFZmxmsgNilLiYzSwG/Bu5z928W85rDPiAGUTqbo70rgwORGRgkDMyMrd0ZNnem2dTRw5bONJs702SyjlnYD6azObozWQCieAf5ans3r2zpYkNHD1t7MmztyVKXimiqTZKKjI7uLB3x9M6ebN8y3ZmB//pXM0iYkTCoT6R5Z+Ip3pJYzpLUm1nWcAxRTS3JhJFMJGiqSzKqPkUqStCdztKZzhIljLpURH0qoi6VoD4V0RAHXF0yQSbnpLM56pIRYxprGFGXpK0rw+a2Dry7jUTDWOpqIhJmGFCbSjC2sZZxjTU09rTQ+PB/k3r5r2TGH0J6wuF0jZ/O1lGHkBs5ib1G11ObrPBAdzXr6QhdQKWO+QwhgxUQSeBvwMnAamAh8CF3X5K3zBnAJYSzmI4Fvu3uM+Ozm34AbHT3y4p9TQWEZLI5MnErKJNzutJZtvZk6Upn6cnk6MnmyGTD/Kx7b4cFHd0ZtnSmae/KkM6FZXLuuNP3O+vxdrNOTzbL1u4srV0ZujPZ0OrK5mjrytDamaYnm6O+JqI2GZGNyxF+cnRlslTw5MHXMIO9R9VTl0rQ0R0CKxUZtcmIxtqIcY21jGlM4Q7dmRw59zjIIgzI5EJBa5OJvpZabyutM52loztDzp2aKEEqSlCXCsslE9Y34tFYm2RkXYoRdcm+9XuXS0UJMtnwdzEzUgkjFYWg7T2DL5PN0ZnOUp+KSMbTcjmnK5OlNhmFU8albINyFpO7Z8zsEuA+wmmuN7v7EjO7OJ4/F5hPCIcVhNNcPxqvfgJwIfC0mT0RT7va3edXqrxSHZJRgvwD5p1eqDgI3J2udI627jTd6RypKEEyMrrSWTZ29NDWlWFEXZIxDTXUJhN9odIbVL3LbWjvoSsTgi+bc1JRglRk1CTDzjrnsGrjVl7euDXulgutmEzO6c7kaOtKs7Gjh2fXtRFZaOWYhe13puMWXdyt1J3J9YVtfiutsSYikbC4FZgb0OCrS4Uw6Epve72GmhAI7d2ZvtcaUZekqTZJIi5rMjKSCcPM6OwJLc26ZMS4phrGNsZn+SWM+pokYxtSjG6oAUL3quMYFndRhr9LlAgtNzNoqk0xrqmGkXUpHCe3gwZrwiCRCH+PumRETdLI5sIBR0NNaA3Xxy3DKLGtzBACsLUrfI1AU22yLxjzuXvf8pVS0esg3mhqQYhUXjbn9GRy1CYTJPKO3t2ddDYc2Weyr22dtXVlaOtKszVudXTHoZfO5EjGwQaQzoZtd3RnaOvO4O401aaor0nQ2ZOjtStNNueMrEvSUJtka0+W1s40Hd2hezOX18oLO+LQaunOZNnQ3sPGrT1942xbe0LQbukMO+LeLlF3JzcIu8UoYTTWRNQkE2zemu5rvQHUp0KLr6EmSc6d1s40bd0ZknH35cRRdfz28vKuXB+UFoSIVKfewf/+zIyaZDhizje2seaNKlpZcrkwHtb/aDx0U4bWWW9XY1tXho0dPbR2prH4yL/QQbx7CMxs3FrrSmdJ55woHsvqTGdp7w7jZtmc93WZdXRn6cnmGNOQYmxjLQa0d8fh2hNacBBaxk21yb5u1NpUZS6oVUCIyLCW2M4YRpQwon6n3o6oS7H36AG+V9huTHdzFRGRghQQIiJSkAJCREQKUkCIiEhBCggRESlIASEiIgUpIEREpCAFhIiIFFRVt9owsxag3C+EGA+8OoDFGUyqy+5Jddl9VVN9Sq3Lfu4+odCMqgqIXWFmi7Z3P5KhRnXZPakuu69qqs9A1kVdTCIiUpACQkREClJAbHPDYBdgAKkuuyfVZfdVTfUZsLpoDEJERApSC0JERApSQIiISEHDPiDMbJaZLTezFWZ25WCXpxRmto+Z/cHMlpnZEjO7NJ4+1szuN7Pn4t9jBrusxTKzyMweN7Nfx8+Hcl1Gm9mdZvZs/Dd661Ctj5ldHv+PPWNmt5tZ3VCpi5ndbGbrzeyZvGnbLbuZXRXvD5ab2bsHp9SFbacu/xX/jz1lZneb2ei8ebtUl2EdEGYWAdcCpwHTgQ+a2fTBLVVJMsDn3P1NwHHAp+PyXwk84O4HAQ/Ez4eKS4Flec+Hcl2uAe5192nAEYR6Dbn6mNkk4LPADHc/DIiAOQydunwfmNVvWsGyx5+fOcCh8TrfjfcTu4vv8/q63A8c5u6HA38DroKBqcuwDghgJrDC3V9w9x7gDmD2IJepaO6+1t0fix+3EXZAkwh1+EG82A+AswelgCUys8nAGcCNeZOHal1GAu8AbgJw9x5338wQrQ/h64nrzSwJNABrGCJ1cfc/ARv7Td5e2WcDd7h7t7u/CKwg7Cd2C4Xq4u6/dfdM/PRhYHL8eJfrMtwDYhKwKu95czxtyDGzKcBRwCPAnu6+FkKIAHsMYtFK8S3gi0Aub9pQrcv+QAtwS9xldqOZNTIE6+Puq4FvAC8Da4Et7v5bhmBd8myv7EN9n/APwG/ix7tcl+EeEIW+rXzInfdrZk3Az4HL3L11sMtTDjM7E1jv7osHuywDJAkcDVzn7kcBHey+XTA7FPfPzwamAnsDjWZ2weCWqmKG7D7BzL5E6Ha+rXdSgcVKqstwD4hmYJ+855MJTechw8xShHC4zd3viie/YmYT4/kTgfWDVb4SnACcZWYvEbr6TjKzWxmadYHwv9Xs7o/Ez+8kBMZQrM8pwIvu3uLuaeAu4HiGZl16ba/sQ3KfYGYfBs4EzvdtF7ftcl2Ge0AsBA4ys6lmVkMY0Jk3yGUqmpkZoY97mbt/M2/WPODD8eMPA798o8tWKne/yt0nu/sUwt/h9+5+AUOwLgDuvg5YZWaHxJNOBpYyNOvzMnCcmTXE/3MnE8a7hmJdem2v7POAOWZWa2ZTgYOARwehfEUzs1nAFcBZ7r41b9au18Xdh/UPcDph5P954EuDXZ4Sy/42QpPxKeCJ+Od0YBzhzIzn4t9jB7usJdbrRODX8eMhWxfgSGBR/Pf5BTBmqNYH+GfgWeAZ4EdA7VCpC3A7YewkTTiq/tiOyg58Kd4fLAdOG+zyF1GXFYSxht59wNyBqotutSEiIgUN9y4mERHZDgWEiIgUpIAQEZGCFBAiIlKQAkJERApSQIjsBszsxN472IrsLhQQIiJSkAJCpARmdoGZPWpmT5jZ9fH3V7Sb2X+b2WNm9oCZTYiXPdLMHs67T/+YePqBZvY7M3syXueAePNNed8fcVt81bLIoFFAiBTJzN4EfAA4wd2PBLLA+UAj8Ji7Hw38EfhKvMoPgSs83Kf/6bzptwHXuvsRhHsarY2nHwVcRvhukv0J96cSGTTJwS6AyBByMvAWYGF8cF9PuMlbDvhJvMytwF1mNgoY7e5/jKf/APiZmY0AJrn73QDu3gUQb+9Rd2+Onz8BTAH+UvFaiWyHAkKkeAb8wN2ves1Esy/3W25H96/ZUbdRd97jLPp8yiBTF5NI8R4AzjWzPaDve433I3yOzo2X+RDwF3ffAmwys7fH0y8E/ujh+zqazezseBu1ZtbwRlZCpFg6QhEpkrsvNbP/A/zWzBKEO2p+mvBlQIea2WJgC2GcAsJtpOfGAfAC8NF4+oXA9Wb2L/E2znsDqyFSNN3NVWQXmVm7uzcNdjlEBpq6mEREpCC1IEREpCC1IEREpCAFhIiIFKSAEBGRghQQIiJSkAJCREQK+v9RQnc9VsnnfAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##################\n",
    "# REPORTS\n",
    "##################\n",
    "\n",
    "reports.plotHistory( hist )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e495c47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black image found\n",
      "Black image found\n",
      "Images count =2309\n",
      "Best RMSENZ  =2181 (0.94)\n",
      "Best MAENZ   =2181 (0.94)\n",
      "Best Accuracy=2021 (0.88)\n",
      "RMSE-NZ  Pred=0.0239  Noisy=0.0943\n",
      "MAE-NZ   Pred=0.0204  Noisy=0.0904\n",
      "PSNR     Pred=20.4 dB Noisy=9.3 dB\n",
      "Accuracy Pred=0.41    Noisy=0.09\n",
      "SSM      Pred=0.95    Noisy=0.67\n",
      "HOG MSE  Pred=0.08    Noisy=0.12\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# PREDICTIONS\n",
    "##################\n",
    "ACCURACY_THRESHOLD = 0.01\n",
    "predictions_metrics, predictions_headers \\\n",
    "    = reports.calcPredictionMetrics( model, val_noisy, val_nitid, ACCURACY_THRESHOLD, \\\n",
    "                                    save_pred = True, save_path = DEST_TESTS, \\\n",
    "                                    noisy_files = val_noisy_files, nitid_files = val_nitid_files, \\\n",
    "                                    max_nitid= radiance_limits.nitid_max  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7dbc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_noisy_files, test_nitid_files, test_noisy, test_nitid = dsutils.readDataset( IMG_PATH_TEST, hyperparams.IMG_WIDTH, hyperparams.IMG_HEIGHT, radiance_limits)\n",
    "test_noisy, test_nitid = dsutils.reshapeDataset( test_noisy, test_nitid,  hyperparams.IMG_WIDTH, hyperparams.IMG_HEIGHT )\n",
    "test_indexes = np.arange(0,test_noisy.shape[0])\n",
    "\n",
    "reports.predictByIndexes( model, test_noisy, test_nitid, test_noisy_files, test_nitid_files, test_indexes, ACCURACY_THRESHOLD )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f9e4309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Projects/VenusDenoise/saves/unet-100_1000-64-a\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('C:/Projects/VenusDenoise/saves/unet-100_1000-64-a')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
