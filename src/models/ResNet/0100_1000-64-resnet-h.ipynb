{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1420dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################\n",
    "# DESCRIPTION: \n",
    "# RESULTS:     \n",
    "#              \n",
    "##############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "144dbf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# CONFIG & HYPERPARAMS\n",
    "######################\n",
    "\n",
    "import os\n",
    "\n",
    "class HyperParams:\n",
    "    pass\n",
    "\n",
    "IMG_PATH = \"C:/Projects/VenusDenoise/dataset/cases/64/0100_1000/\"\n",
    "\n",
    "IMG_PATH_VALID = IMG_PATH + \"validation/\"\n",
    "IMG_PATH_TEST = IMG_PATH + \"test/\"\n",
    "IMG_PATH_TRAIN = IMG_PATH\n",
    "\n",
    "IMG_PATH_TRAIN = IMG_PATH\n",
    "\n",
    "hyperparams = HyperParams()\n",
    "hyperparams.IMG_WIDTH = 64\n",
    "hyperparams.IMG_HEIGHT = 64\n",
    "hyperparams.EPOCHS = 200\n",
    "hyperparams.BATCH_SIZE = 32\n",
    "\n",
    "hyperparams.NUM_CHANNELS = 32\n",
    "hyperparams.NUM_RES_BLOCKS = 5\n",
    "\n",
    "hyperparams.LOSS = 'mae_nz'\n",
    "\n",
    "IMG_WIDTH = hyperparams.IMG_WIDTH\n",
    "IMG_HEIGHT = hyperparams.IMG_HEIGHT\n",
    "\n",
    "IMG_CASE = str(IMG_WIDTH) +  \"/0100_1000\"\n",
    "MODEL_NAME = \"0100_1000-64-resnet-h\"\n",
    "\n",
    "DEST_TESTS = os.path.abspath(os.path.join('../../../out_tests/', MODEL_NAME))\n",
    "\n",
    "class RadianceLimits:\n",
    "    pass\n",
    "radiance_limits = RadianceLimits()\n",
    "radiance_limits.noisy_min = 0\n",
    "radiance_limits.noisy_max = 0.0898\n",
    "radiance_limits.nitid_min = 0\n",
    "radiance_limits.nitid_max = 0.3248\n",
    "\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "hyperparams.OPTIMIZER = Nadam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be827de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# IMPORTS\n",
    "##################\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow \n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('../../support/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import DatasetUtilsTifF as dsutils\n",
    "import TrainModelC as train\n",
    "import ReportsK as reports\n",
    "import ResnetBatchE as model_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c24c07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15905293015538475709\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1721976832\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10885296496355118257\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:2b:00.0, compute capability: 8.6\"\n",
      "]\n",
      "Tensorflow version: 2.6.0\n",
      "Keras Version: 2.6.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "print(f\"Tensorflow version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tf.keras.__version__}\")\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a22f1b6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Operands could not be broadcast together with shapes (64, 64, 512) (64, 64, 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m##################\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# MODEL DEFINITION\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m##################\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_factory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuildModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhyperparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mget_config()\n",
      "File \u001b[1;32mC:\\Projects\\VenusDenoise\\src\\models\\ResNet\\ResnetBatchE.py:32\u001b[0m, in \u001b[0;36mbuildModel\u001b[1;34m(hyperparameters)\u001b[0m\n\u001b[0;32m     28\u001b[0m     hyperparameters\u001b[38;5;241m.\u001b[39mOPTIMIZER \u001b[38;5;241m=\u001b[39m Adam(beta_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m)\n\u001b[0;32m     30\u001b[0m HYPER \u001b[38;5;241m=\u001b[39m hyperparameters\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_resnet_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHYPER\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMG_HEIGHT\u001b[49m\u001b[43m,\u001b[49m\u001b[43mHYPER\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMG_WIDTH\u001b[49m\u001b[43m,\u001b[49m\u001b[43mHYPER\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNUM_CHANNELS\u001b[49m\u001b[43m,\u001b[49m\u001b[43mHYPER\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNUM_RES_BLOCKS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHYPER\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOPTIMIZER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHYPER\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLOSS\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Projects\\VenusDenoise\\src\\models\\ResNet\\ResnetBatchE.py:57\u001b[0m, in \u001b[0;36mbuild_resnet_model\u001b[1;34m(height, width, num_channels, num_res_blocks, optimizer, loss_function)\u001b[0m\n\u001b[0;32m     55\u001b[0m X \u001b[38;5;241m=\u001b[39m convolutional_block(X, f \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, filters \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m], stage \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, block\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, s \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     56\u001b[0m X \u001b[38;5;241m=\u001b[39m identity_block(X, \u001b[38;5;241m3\u001b[39m, [\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m], stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, block\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 57\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43midentity_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m X \u001b[38;5;241m=\u001b[39m identity_block(X, \u001b[38;5;241m3\u001b[39m, [\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m512\u001b[39m], stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, block\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Stage 4 (≈6 lines)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Projects\\VenusDenoise\\src\\models\\ResNet\\ResnetBatchE.py:149\u001b[0m, in \u001b[0;36midentity_block\u001b[1;34m(X, f, filters, stage, block)\u001b[0m\n\u001b[0;32m    146\u001b[0m X \u001b[38;5;241m=\u001b[39m BatchNormalization(axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, name \u001b[38;5;241m=\u001b[39m bn_name_base \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2c\u001b[39m\u001b[38;5;124m'\u001b[39m)(X)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mAdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_shortcut\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m X \u001b[38;5;241m=\u001b[39m Activation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(X)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py:976\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;66;03m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;66;03m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;66;03m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _in_functional_construction_mode(\u001b[38;5;28mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[1;32m--> 976\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_functional_construction_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;66;03m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[0;32m    980\u001b[0m call_context \u001b[38;5;241m=\u001b[39m base_layer_utils\u001b[38;5;241m.\u001b[39mcall_context()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py:1114\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1109\u001b[0m     training_arg_passed_by_framework \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m call_context\u001b[38;5;241m.\u001b[39menter(\n\u001b[0;32m   1112\u001b[0m     layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, inputs\u001b[38;5;241m=\u001b[39minputs, build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39mtraining_value):\n\u001b[0;32m   1113\u001b[0m   \u001b[38;5;66;03m# Check input assumptions set after layer building, e.g. input shape.\u001b[39;00m\n\u001b[1;32m-> 1114\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_keras_tensor_symbolic_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1117\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA layer\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms `call` method should return a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1119\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensor or a list of Tensors, not None \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1120\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(layer: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py:848\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    846\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(keras_tensor\u001b[38;5;241m.\u001b[39mKerasTensor, output_signature)\n\u001b[0;32m    847\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 848\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_output_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py:886\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_scope()):  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    881\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m    882\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[0;32m    883\u001b[0m     \u001b[38;5;66;03m# Build layer if applicable (if the `build` method has been\u001b[39;00m\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# overridden).\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;66;03m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[39;00m\n\u001b[1;32m--> 886\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    887\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[0;32m    888\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\base_layer.py:2659\u001b[0m, in \u001b[0;36mLayer._maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_is_default\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   2655\u001b[0m   \u001b[38;5;66;03m# Any setup work performed only once should happen in an `init_scope`\u001b[39;00m\n\u001b[0;32m   2656\u001b[0m   \u001b[38;5;66;03m# to avoid creating symbolic Tensors that will later pollute any eager\u001b[39;00m\n\u001b[0;32m   2657\u001b[0m   \u001b[38;5;66;03m# operations.\u001b[39;00m\n\u001b[0;32m   2658\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m tf_utils\u001b[38;5;241m.\u001b[39mmaybe_init_scope(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m-> 2659\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shapes\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint:disable=not-callable\u001b[39;00m\n\u001b[0;32m   2660\u001b[0m \u001b[38;5;66;03m# We must set also ensure that the layer is marked as built, and the build\u001b[39;00m\n\u001b[0;32m   2661\u001b[0m \u001b[38;5;66;03m# shape is stored since user defined build functions may not be calling\u001b[39;00m\n\u001b[0;32m   2662\u001b[0m \u001b[38;5;66;03m# `super.build()`\u001b[39;00m\n\u001b[0;32m   2663\u001b[0m Layer\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m, input_shapes)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\tf_utils.py:259\u001b[0m, in \u001b[0;36mshape_type_conversion.<locals>.wrapper\u001b[1;34m(instance, input_shape)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m   input_shape \u001b[38;5;241m=\u001b[39m convert_shapes(input_shape, to_tuples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 259\u001b[0m output_shape \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m# Return shapes from `fn` as TensorShapes.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\layers\\merge.py:107\u001b[0m, in \u001b[0;36m_Merge.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m     shape \u001b[38;5;241m=\u001b[39m input_shape[i][\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 107\u001b[0m   output_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_elemwise_op_output_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# If the inputs have different ranks, we have to reshape them\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# to make them broadcastable.\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m input_shape \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlen\u001b[39m, input_shape))) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\layers\\merge.py:78\u001b[0m, in \u001b[0;36m_Merge._compute_elemwise_op_output_shape\u001b[1;34m(self, shape1, shape2)\u001b[0m\n\u001b[0;32m     76\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m j:\n\u001b[1;32m---> 78\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     79\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOperands could not be broadcast \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     80\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtogether with shapes \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(shape1) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(shape2))\n\u001b[0;32m     81\u001b[0m     output_shape\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(output_shape)\n",
      "\u001b[1;31mValueError\u001b[0m: Operands could not be broadcast together with shapes (64, 64, 512) (64, 64, 64)"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# MODEL DEFINITION\n",
    "##################\n",
    "\n",
    "model = model_factory.buildModel(hyperparams)\n",
    "model.summary()\n",
    "model.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1de709",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# PREPARE DATA\n",
    "##################\n",
    "\n",
    "train_noisy_files, train_nitid_files, train_noisy, train_nitid = dsutils.readDataset( IMG_PATH_TRAIN, hyperparams.IMG_WIDTH, hyperparams.IMG_HEIGHT, radiance_limits)\n",
    "val_noisy_files, val_nitid_files, val_noisy, val_nitid = dsutils.readDataset( IMG_PATH_VALID, hyperparams.IMG_WIDTH, hyperparams.IMG_HEIGHT, radiance_limits)\n",
    "\n",
    "train_noisy, train_nitid = dsutils.reshapeDataset( train_noisy, train_nitid, hyperparams.IMG_WIDTH, hyperparams.IMG_HEIGHT )\n",
    "val_noisy, val_nitid = dsutils.reshapeDataset( val_noisy, val_nitid, hyperparams.IMG_WIDTH, hyperparams.IMG_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df4c982",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# TRAIN MODEL\n",
    "##################\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "set_session(sess)\n",
    "\n",
    "hist = train.fit( model, hyperparams, train_noisy, train_nitid, val_noisy, val_nitid, patience = 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e98d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# REPORTS\n",
    "##################\n",
    "reports.plotHistory( hist )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa69a1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.abspath(os.path.join('../../../saves/', MODEL_NAME)), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99fc06b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
