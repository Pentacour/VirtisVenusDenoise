{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1420dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################\n",
    "# DESCRIPTION: \n",
    "# RESULTS:     \n",
    "#              \n",
    "##############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "144dbf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# CONFIG & HYPERPARAMS\n",
    "######################\n",
    "\n",
    "import os\n",
    "\n",
    "class HyperParams:\n",
    "    pass\n",
    "\n",
    "IMG_PATH = \"C:/Projects/VenusDenoise/dataset/cases/64/0100_1000/\"\n",
    "\n",
    "IMG_PATH_VALID = IMG_PATH + \"validation/\"\n",
    "IMG_PATH_TEST = IMG_PATH + \"test/\"\n",
    "IMG_PATH_TRAIN = IMG_PATH\n",
    "\n",
    "hyperparams = HyperParams()\n",
    "hyperparams.IMG_WIDTH = 64\n",
    "hyperparams.IMG_HEIGHT = 64\n",
    "hyperparams.EPOCHS = 320\n",
    "hyperparams.BATCH_SIZE = 32\n",
    "\n",
    "hyperparams.LOSS = 'mean_absolute_error'\n",
    "\n",
    "IMG_WIDTH = hyperparams.IMG_WIDTH\n",
    "IMG_HEIGHT = hyperparams.IMG_HEIGHT\n",
    "\n",
    "IMG_CASE = str(IMG_WIDTH) +  \"/0100_1000\"\n",
    "MODEL_NAME = \"0100_1000-64-convsim-g\"\n",
    "\n",
    "DEST_TESTS = os.path.abspath(os.path.join('../../../out_tests/', MODEL_NAME))\n",
    "\n",
    "class RadianceLimits:\n",
    "    pass\n",
    "radiance_limits = RadianceLimits()\n",
    "radiance_limits.noisy_min = 0\n",
    "radiance_limits.noisy_max = 0.0898\n",
    "radiance_limits.nitid_min = 0\n",
    "radiance_limits.nitid_max = 0.3248\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "hyperparams.OPTIMIZER = RMSprop(learning_rate=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be827de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# IMPORTS\n",
    "##################\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow \n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('../../support/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import DatasetUtilsTifF as dsutils\n",
    "import TrainModelC as train\n",
    "import ReportsK as reports\n",
    "import ConvSimG as model_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a22f1b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 32)   544         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 16, 16)   8208        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 16)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 8, 8, 8)      2056        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 32)   544         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 8, 8, 8)      0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 32)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 16, 16, 16)   2064        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 16, 16, 16)   8208        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 16)   0           conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 16, 16, 16)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 16, 16, 16)   0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 32, 32, 32)   8224        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 32, 32, 32)   8224        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 32)   0           conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 32)   0           conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 32, 32)   0           activation[0][0]                 \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 32)   0           activation_4[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 64, 64, 1)    513         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 64, 64, 1)    513         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 1)    0           conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 64, 1)    0           conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 64, 1)    0           activation_3[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 39,098\n",
      "Trainable params: 39,098\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'RMSprop',\n",
       " 'learning_rate': 0.0005,\n",
       " 'decay': 0.0,\n",
       " 'rho': 0.9,\n",
       " 'momentum': 0.0,\n",
       " 'epsilon': 1e-07,\n",
       " 'centered': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################\n",
    "# MODEL DEFINITION\n",
    "##################\n",
    "model = model_factory.buildModel(hyperparams)\n",
    "model.summary()\n",
    "model.optimizer.get_config()\n",
    "model.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f1de709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read dataset. Path: C:/Projects/VenusDenoise/dataset/cases/64/0100_1000/\n",
      "Noisy files:8886\n",
      "Nitid files:8886\n",
      "Read dataset. Path: C:/Projects/VenusDenoise/dataset/cases/64/0100_1000/validation/\n",
      "Noisy files:2209\n",
      "Nitid files:2209\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# PREPARE DATA\n",
    "##################\n",
    "\n",
    "train_noisy_files, train_nitid_files, train_noisy, train_nitid = dsutils.readDataset( IMG_PATH_TRAIN, hyperparams.IMG_WIDTH, hyperparams.IMG_HEIGHT, radiance_limits)\n",
    "val_noisy_files, val_nitid_files, val_noisy, val_nitid = dsutils.readDataset( IMG_PATH_VALID, hyperparams.IMG_WIDTH, hyperparams.IMG_HEIGHT, radiance_limits)\n",
    "\n",
    "train_noisy, train_nitid = dsutils.reshapeDataset( train_noisy, train_nitid, hyperparams.IMG_WIDTH, hyperparams.IMG_HEIGHT )\n",
    "val_noisy, val_nitid = dsutils.reshapeDataset( val_noisy, val_nitid, hyperparams.IMG_WIDTH, hyperparams.IMG_HEIGHT )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1df4c982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:2b:00.0, compute capability: 8.6\n",
      "\n",
      "Epoch 1/320\n",
      "278/278 [==============================] - 9s 10ms/step - loss: 0.0405 - val_loss: 0.0237\n",
      "Epoch 2/320\n",
      "278/278 [==============================] - 2s 8ms/step - loss: 0.0297 - val_loss: 0.0223\n",
      "Epoch 3/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0283 - val_loss: 0.0265\n",
      "Epoch 4/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0275 - val_loss: 0.0229\n",
      "Epoch 5/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0269 - val_loss: 0.0223\n",
      "Epoch 6/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0265 - val_loss: 0.0216\n",
      "Epoch 7/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0263 - val_loss: 0.0224\n",
      "Epoch 8/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0258 - val_loss: 0.0227\n",
      "Epoch 9/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0256 - val_loss: 0.0212\n",
      "Epoch 10/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0253 - val_loss: 0.0228\n",
      "Epoch 11/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0250 - val_loss: 0.0263\n",
      "Epoch 12/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0249 - val_loss: 0.0260\n",
      "Epoch 13/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0248 - val_loss: 0.0255\n",
      "Epoch 14/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0245 - val_loss: 0.0287\n",
      "Epoch 15/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0244 - val_loss: 0.0224\n",
      "Epoch 16/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0245 - val_loss: 0.0211\n",
      "Epoch 17/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0241 - val_loss: 0.0238\n",
      "Epoch 18/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0241 - val_loss: 0.0222\n",
      "Epoch 19/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0240 - val_loss: 0.0251\n",
      "Epoch 20/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0238 - val_loss: 0.0206\n",
      "Epoch 21/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0239 - val_loss: 0.0208\n",
      "Epoch 22/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0238 - val_loss: 0.0212\n",
      "Epoch 23/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0237 - val_loss: 0.0221\n",
      "Epoch 24/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0237 - val_loss: 0.0234\n",
      "Epoch 25/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0236 - val_loss: 0.0245\n",
      "Epoch 26/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0234 - val_loss: 0.0216\n",
      "Epoch 27/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0234 - val_loss: 0.0238\n",
      "Epoch 28/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0235 - val_loss: 0.0220\n",
      "Epoch 29/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0233 - val_loss: 0.0224\n",
      "Epoch 30/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0233 - val_loss: 0.0211\n",
      "Epoch 31/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0232 - val_loss: 0.0210\n",
      "Epoch 32/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0232 - val_loss: 0.0228\n",
      "Epoch 33/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0233 - val_loss: 0.0211\n",
      "Epoch 34/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0231 - val_loss: 0.0226\n",
      "Epoch 35/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0230 - val_loss: 0.0235\n",
      "Epoch 36/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0230 - val_loss: 0.0207\n",
      "Epoch 37/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0230 - val_loss: 0.0240\n",
      "Epoch 38/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0230 - val_loss: 0.0237\n",
      "Epoch 39/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0229 - val_loss: 0.0208\n",
      "Epoch 40/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0229 - val_loss: 0.0233\n",
      "Epoch 41/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0228 - val_loss: 0.0207\n",
      "Epoch 42/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0228 - val_loss: 0.0203\n",
      "Epoch 43/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0228 - val_loss: 0.0209\n",
      "Epoch 44/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0228 - val_loss: 0.0223\n",
      "Epoch 45/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0228 - val_loss: 0.0201\n",
      "Epoch 46/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0226 - val_loss: 0.0211\n",
      "Epoch 47/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0226 - val_loss: 0.0203\n",
      "Epoch 48/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0226 - val_loss: 0.0209\n",
      "Epoch 49/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0226 - val_loss: 0.0231\n",
      "Epoch 50/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0225 - val_loss: 0.0203\n",
      "Epoch 51/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0226 - val_loss: 0.0213\n",
      "Epoch 52/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0225 - val_loss: 0.0239\n",
      "Epoch 53/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0224 - val_loss: 0.0211\n",
      "Epoch 54/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0225 - val_loss: 0.0214\n",
      "Epoch 55/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0224 - val_loss: 0.0211\n",
      "Epoch 56/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0224 - val_loss: 0.0216\n",
      "Epoch 57/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0223 - val_loss: 0.0207\n",
      "Epoch 58/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0224 - val_loss: 0.0226\n",
      "Epoch 59/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0223 - val_loss: 0.0214\n",
      "Epoch 60/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0222 - val_loss: 0.0203\n",
      "Epoch 61/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0222 - val_loss: 0.0251\n",
      "Epoch 62/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0224 - val_loss: 0.0212\n",
      "Epoch 63/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0222 - val_loss: 0.0226\n",
      "Epoch 64/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0223 - val_loss: 0.0222\n",
      "Epoch 65/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0222 - val_loss: 0.0243\n",
      "Epoch 66/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0220 - val_loss: 0.0216\n",
      "Epoch 67/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0221 - val_loss: 0.0217\n",
      "Epoch 68/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0220 - val_loss: 0.0225\n",
      "Epoch 69/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0221 - val_loss: 0.0218\n",
      "Epoch 70/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0221 - val_loss: 0.0212\n",
      "Epoch 71/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0220 - val_loss: 0.0207\n",
      "Epoch 72/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0220 - val_loss: 0.0257\n",
      "Epoch 73/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0220 - val_loss: 0.0232\n",
      "Epoch 74/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0219 - val_loss: 0.0223\n",
      "Epoch 75/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0219 - val_loss: 0.0212\n",
      "Epoch 76/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0219 - val_loss: 0.0205\n",
      "Epoch 77/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0219 - val_loss: 0.0217\n",
      "Epoch 78/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0219 - val_loss: 0.0208\n",
      "Epoch 79/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0218 - val_loss: 0.0223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0219 - val_loss: 0.0203\n",
      "Epoch 81/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0218 - val_loss: 0.0204\n",
      "Epoch 82/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0218 - val_loss: 0.0207\n",
      "Epoch 83/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0218 - val_loss: 0.0206\n",
      "Epoch 84/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0218 - val_loss: 0.0221\n",
      "Epoch 85/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0217 - val_loss: 0.0205\n",
      "Epoch 86/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0217 - val_loss: 0.0220\n",
      "Epoch 87/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0217 - val_loss: 0.0204\n",
      "Epoch 88/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0216 - val_loss: 0.0204\n",
      "Epoch 89/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0217 - val_loss: 0.0240\n",
      "Epoch 90/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0216 - val_loss: 0.0205\n",
      "Epoch 91/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0216 - val_loss: 0.0229\n",
      "Epoch 92/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0216 - val_loss: 0.0236\n",
      "Epoch 93/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0215 - val_loss: 0.0205\n",
      "Epoch 94/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0215 - val_loss: 0.0230\n",
      "Epoch 95/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0215 - val_loss: 0.0211\n",
      "Epoch 96/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0215 - val_loss: 0.0241\n",
      "Epoch 97/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0215 - val_loss: 0.0238\n",
      "Epoch 98/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0215 - val_loss: 0.0236\n",
      "Epoch 99/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0214 - val_loss: 0.0205\n",
      "Epoch 100/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0214 - val_loss: 0.0221\n",
      "Epoch 101/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0215 - val_loss: 0.0206\n",
      "Epoch 102/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0213 - val_loss: 0.0209\n",
      "Epoch 103/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0214 - val_loss: 0.0216\n",
      "Epoch 104/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0213 - val_loss: 0.0203\n",
      "Epoch 105/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0213 - val_loss: 0.0207\n",
      "Epoch 106/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0213 - val_loss: 0.0240\n",
      "Epoch 107/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0213 - val_loss: 0.0211\n",
      "Epoch 108/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0213 - val_loss: 0.0207\n",
      "Epoch 109/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0213 - val_loss: 0.0207\n",
      "Epoch 110/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0212 - val_loss: 0.0209\n",
      "Epoch 111/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0212 - val_loss: 0.0209\n",
      "Epoch 112/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0213 - val_loss: 0.0211\n",
      "Epoch 113/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0213 - val_loss: 0.0205\n",
      "Epoch 114/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0212 - val_loss: 0.0216\n",
      "Epoch 115/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0212 - val_loss: 0.0209\n",
      "Epoch 116/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0212 - val_loss: 0.0216\n",
      "Epoch 117/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0211 - val_loss: 0.0218\n",
      "Epoch 118/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0212 - val_loss: 0.0225\n",
      "Epoch 119/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0211 - val_loss: 0.0253\n",
      "Epoch 120/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0211 - val_loss: 0.0217\n",
      "Epoch 121/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0211 - val_loss: 0.0235\n",
      "Epoch 122/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0210 - val_loss: 0.0213\n",
      "Epoch 123/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0210 - val_loss: 0.0211\n",
      "Epoch 124/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0210 - val_loss: 0.0228\n",
      "Epoch 125/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0211 - val_loss: 0.0234\n",
      "Epoch 126/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0210 - val_loss: 0.0212\n",
      "Epoch 127/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0210 - val_loss: 0.0211\n",
      "Epoch 128/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0210 - val_loss: 0.0229\n",
      "Epoch 129/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0210 - val_loss: 0.0218\n",
      "Epoch 130/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0209 - val_loss: 0.0218\n",
      "Epoch 131/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0209 - val_loss: 0.0218\n",
      "Epoch 132/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0209 - val_loss: 0.0251\n",
      "Epoch 133/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0209 - val_loss: 0.0217\n",
      "Epoch 134/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0208 - val_loss: 0.0220\n",
      "Epoch 135/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0208 - val_loss: 0.0210\n",
      "Epoch 136/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0209 - val_loss: 0.0223\n",
      "Epoch 137/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0208 - val_loss: 0.0216\n",
      "Epoch 138/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0208 - val_loss: 0.0213\n",
      "Epoch 139/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0208 - val_loss: 0.0223\n",
      "Epoch 140/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0208 - val_loss: 0.0217\n",
      "Epoch 141/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0208 - val_loss: 0.0208\n",
      "Epoch 142/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0208 - val_loss: 0.0216\n",
      "Epoch 143/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0207 - val_loss: 0.0212\n",
      "Epoch 144/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0208 - val_loss: 0.0225\n",
      "Epoch 145/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0208 - val_loss: 0.0213\n",
      "Epoch 146/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0207 - val_loss: 0.0211\n",
      "Epoch 147/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0207 - val_loss: 0.0216\n",
      "Epoch 148/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0206 - val_loss: 0.0216\n",
      "Epoch 149/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0207 - val_loss: 0.0203\n",
      "Epoch 150/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0207 - val_loss: 0.0207\n",
      "Epoch 151/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0206 - val_loss: 0.0201\n",
      "Epoch 152/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0207 - val_loss: 0.0205\n",
      "Epoch 153/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0207 - val_loss: 0.0221\n",
      "Epoch 154/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0206 - val_loss: 0.0231\n",
      "Epoch 155/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0206 - val_loss: 0.0251\n",
      "Epoch 156/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0206 - val_loss: 0.0205\n",
      "Epoch 157/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0205 - val_loss: 0.0212\n",
      "Epoch 158/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0206 - val_loss: 0.0207\n",
      "Epoch 159/320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0206 - val_loss: 0.0201\n",
      "Epoch 160/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0205 - val_loss: 0.0203\n",
      "Epoch 161/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0205 - val_loss: 0.0210\n",
      "Epoch 162/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0205 - val_loss: 0.0207\n",
      "Epoch 163/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0205 - val_loss: 0.0203\n",
      "Epoch 164/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0205 - val_loss: 0.0210\n",
      "Epoch 165/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0206 - val_loss: 0.0211\n",
      "Epoch 166/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0204 - val_loss: 0.0202\n",
      "Epoch 167/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0204 - val_loss: 0.0200\n",
      "Epoch 168/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0205 - val_loss: 0.0203\n",
      "Epoch 169/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0204 - val_loss: 0.0221\n",
      "Epoch 170/320\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.0203 - val_loss: 0.0202\n",
      "Epoch 171/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0204 - val_loss: 0.0209\n",
      "Epoch 172/320\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.0203 - val_loss: 0.0206\n",
      "Epoch 173/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0204 - val_loss: 0.0208\n",
      "Epoch 174/320\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.0204 - val_loss: 0.0214\n",
      "Epoch 175/320\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.0203 - val_loss: 0.0199\n",
      "Epoch 176/320\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.0203 - val_loss: 0.0211\n",
      "Epoch 177/320\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.0203 - val_loss: 0.0219\n",
      "Epoch 178/320\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.0204 - val_loss: 0.0217\n",
      "Epoch 179/320\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.0203 - val_loss: 0.0207\n",
      "Epoch 180/320\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.0202 - val_loss: 0.0204\n",
      "Epoch 181/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0203 - val_loss: 0.0202\n",
      "Epoch 182/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0202 - val_loss: 0.0233\n",
      "Epoch 183/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0202 - val_loss: 0.0214\n",
      "Epoch 184/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0202 - val_loss: 0.0204\n",
      "Epoch 185/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0203 - val_loss: 0.0211\n",
      "Epoch 186/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0203 - val_loss: 0.0204\n",
      "Epoch 187/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0202 - val_loss: 0.0203\n",
      "Epoch 188/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0202 - val_loss: 0.0203\n",
      "Epoch 189/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0203 - val_loss: 0.0204\n",
      "Epoch 190/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0202 - val_loss: 0.0212\n",
      "Epoch 191/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0202 - val_loss: 0.0217\n",
      "Epoch 192/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0201 - val_loss: 0.0211\n",
      "Epoch 193/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0202 - val_loss: 0.0215\n",
      "Epoch 194/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0201 - val_loss: 0.0209\n",
      "Epoch 195/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0202 - val_loss: 0.0212\n",
      "Epoch 196/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0202 - val_loss: 0.0201\n",
      "Epoch 197/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0201 - val_loss: 0.0228\n",
      "Epoch 198/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0202 - val_loss: 0.0213\n",
      "Epoch 199/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0200 - val_loss: 0.0212\n",
      "Epoch 200/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0201 - val_loss: 0.0201\n",
      "Epoch 201/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0200 - val_loss: 0.0209\n",
      "Epoch 202/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0201 - val_loss: 0.0201\n",
      "Epoch 203/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0200 - val_loss: 0.0197\n",
      "Epoch 204/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0201 - val_loss: 0.0219\n",
      "Epoch 205/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0200 - val_loss: 0.0231\n",
      "Epoch 206/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0200 - val_loss: 0.0215\n",
      "Epoch 207/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0200 - val_loss: 0.0218\n",
      "Epoch 208/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0199 - val_loss: 0.0204\n",
      "Epoch 209/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0200 - val_loss: 0.0209\n",
      "Epoch 210/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0200 - val_loss: 0.0205\n",
      "Epoch 211/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0201 - val_loss: 0.0200\n",
      "Epoch 212/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0199 - val_loss: 0.0206\n",
      "Epoch 213/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0199 - val_loss: 0.0210\n",
      "Epoch 214/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0199 - val_loss: 0.0202\n",
      "Epoch 215/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0200 - val_loss: 0.0222\n",
      "Epoch 216/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0199 - val_loss: 0.0246\n",
      "Epoch 217/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0200 - val_loss: 0.0214\n",
      "Epoch 218/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0199 - val_loss: 0.0205\n",
      "Epoch 219/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0199 - val_loss: 0.0207\n",
      "Epoch 220/320\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.0199 - val_loss: 0.0203\n",
      "Epoch 221/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0198 - val_loss: 0.0204\n",
      "Epoch 222/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0199 - val_loss: 0.0221\n",
      "Epoch 223/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0199 - val_loss: 0.0201\n",
      "Epoch 224/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0198 - val_loss: 0.0205\n",
      "Epoch 225/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0197 - val_loss: 0.0210\n",
      "Epoch 226/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0198 - val_loss: 0.0201\n",
      "Epoch 227/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0198 - val_loss: 0.0207\n",
      "Epoch 228/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0198 - val_loss: 0.0204\n",
      "Epoch 229/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0198 - val_loss: 0.0204\n",
      "Epoch 230/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0198 - val_loss: 0.0212\n",
      "Epoch 231/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0198 - val_loss: 0.0213\n",
      "Epoch 232/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0198 - val_loss: 0.0202\n",
      "Epoch 233/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0198 - val_loss: 0.0205\n",
      "Epoch 234/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0198 - val_loss: 0.0235\n",
      "Epoch 235/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0198 - val_loss: 0.0203\n",
      "Epoch 236/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0197 - val_loss: 0.0212\n",
      "Epoch 237/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0198 - val_loss: 0.0197\n",
      "Epoch 238/320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 239/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0196 - val_loss: 0.0208\n",
      "Epoch 240/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 241/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0198 - val_loss: 0.0200\n",
      "Epoch 242/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0196 - val_loss: 0.0202\n",
      "Epoch 243/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0197 - val_loss: 0.0203\n",
      "Epoch 244/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0197 - val_loss: 0.0204\n",
      "Epoch 245/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0197 - val_loss: 0.0226\n",
      "Epoch 246/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0197 - val_loss: 0.0200\n",
      "Epoch 247/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0197 - val_loss: 0.0206\n",
      "Epoch 248/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0196 - val_loss: 0.0206\n",
      "Epoch 249/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0197 - val_loss: 0.0199\n",
      "Epoch 250/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0196 - val_loss: 0.0205\n",
      "Epoch 251/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0196 - val_loss: 0.0208\n",
      "Epoch 252/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0196 - val_loss: 0.0226\n",
      "Epoch 253/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0196 - val_loss: 0.0230\n",
      "Epoch 254/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0196 - val_loss: 0.0204\n",
      "Epoch 255/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0196 - val_loss: 0.0199\n",
      "Epoch 256/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0196 - val_loss: 0.0203\n",
      "Epoch 257/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0196 - val_loss: 0.0208\n",
      "Epoch 258/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0195 - val_loss: 0.0199\n",
      "Epoch 259/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0196 - val_loss: 0.0207\n",
      "Epoch 260/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0195 - val_loss: 0.0212\n",
      "Epoch 261/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0195 - val_loss: 0.0202\n",
      "Epoch 262/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0195 - val_loss: 0.0199\n",
      "Epoch 263/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0195 - val_loss: 0.0206\n",
      "Epoch 264/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0196 - val_loss: 0.0193\n",
      "Epoch 265/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0196 - val_loss: 0.0204\n",
      "Epoch 266/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0195 - val_loss: 0.0205\n",
      "Epoch 267/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0195 - val_loss: 0.0198\n",
      "Epoch 268/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0195 - val_loss: 0.0220\n",
      "Epoch 269/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0195 - val_loss: 0.0202\n",
      "Epoch 270/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0195 - val_loss: 0.0204\n",
      "Epoch 271/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0195 - val_loss: 0.0206\n",
      "Epoch 272/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0194 - val_loss: 0.0202\n",
      "Epoch 273/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0195 - val_loss: 0.0200\n",
      "Epoch 274/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0195 - val_loss: 0.0206\n",
      "Epoch 275/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0195 - val_loss: 0.0207\n",
      "Epoch 276/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0194 - val_loss: 0.0199\n",
      "Epoch 277/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0194 - val_loss: 0.0210\n",
      "Epoch 278/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0194 - val_loss: 0.0201\n",
      "Epoch 279/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0194 - val_loss: 0.0205\n",
      "Epoch 280/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0194 - val_loss: 0.0193\n",
      "Epoch 281/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0194 - val_loss: 0.0217\n",
      "Epoch 282/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0194 - val_loss: 0.0202\n",
      "Epoch 283/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0194 - val_loss: 0.0209\n",
      "Epoch 284/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0194 - val_loss: 0.0198\n",
      "Epoch 285/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0194 - val_loss: 0.0198\n",
      "Epoch 286/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0194 - val_loss: 0.0206\n",
      "Epoch 287/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0193 - val_loss: 0.0200\n",
      "Epoch 288/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0193 - val_loss: 0.0195\n",
      "Epoch 289/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0193 - val_loss: 0.0200\n",
      "Epoch 290/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0193 - val_loss: 0.0209\n",
      "Epoch 291/320\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.0194 - val_loss: 0.0194\n",
      "Epoch 292/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0193 - val_loss: 0.0229\n",
      "Epoch 293/320\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.0193 - val_loss: 0.0222\n",
      "Epoch 294/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0193 - val_loss: 0.0245\n",
      "Epoch 295/320\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.0193 - val_loss: 0.0195\n",
      "Epoch 296/320\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.0192 - val_loss: 0.0201\n",
      "Epoch 297/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0193 - val_loss: 0.0205\n",
      "Epoch 298/320\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.0192 - val_loss: 0.0206\n",
      "Epoch 299/320\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.0193 - val_loss: 0.0204\n",
      "Epoch 300/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0193 - val_loss: 0.0204\n",
      "Epoch 301/320\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.0193 - val_loss: 0.0202\n",
      "Epoch 302/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0193 - val_loss: 0.0196\n",
      "Epoch 303/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0192 - val_loss: 0.0207\n",
      "Epoch 304/320\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.0192 - val_loss: 0.0204\n",
      "Epoch 305/320\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.0192 - val_loss: 0.0198\n",
      "Epoch 306/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0193 - val_loss: 0.0199\n",
      "Epoch 307/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0193 - val_loss: 0.0193\n",
      "Epoch 308/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0192 - val_loss: 0.0204\n",
      "Epoch 309/320\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.0193 - val_loss: 0.0204\n",
      "Epoch 310/320\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.0192 - val_loss: 0.0205\n",
      "Epoch 311/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0191 - val_loss: 0.0197\n",
      "Epoch 312/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0192 - val_loss: 0.0201\n",
      "Epoch 313/320\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0192 - val_loss: 0.0209\n",
      "Epoch 314/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0192 - val_loss: 0.0205\n",
      "Epoch 315/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0192 - val_loss: 0.0232\n",
      "Epoch 316/320\n",
      "278/278 [==============================] - 3s 10ms/step - loss: 0.0192 - val_loss: 0.0198\n",
      "Epoch 317/320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0192 - val_loss: 0.0202\n",
      "Epoch 318/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0192 - val_loss: 0.0211\n",
      "Epoch 319/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0191 - val_loss: 0.0205\n",
      "Epoch 320/320\n",
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0191 - val_loss: 0.0197\n",
      "Train size:8886\n",
      "Valid.size:2209\n",
      "--- 814.3159403800964 seconds ---\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# TRAIN MODEL\n",
    "##################\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "set_session(sess)\n",
    "\n",
    "\n",
    "hist = train.fit( model, hyperparams, train_noisy, train_nitid, val_noisy, val_nitid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14e98d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABSFUlEQVR4nO2dd5xcVd3/39+Z7X2TbJLNbhohkE6AAKEpXQhgUGkCVgR5BBVs4KNYeXx4FJUfFhAURUAUQSRi6BJ6AmmQThJI2ZTd7GZ7L+f3x7l3753ZmdmZzU625Pt+veY1M7fNuXfuPZ/zLeccMcagKIqiKPESGOgCKIqiKEMLFQ5FURQlIVQ4FEVRlIRQ4VAURVESQoVDURRFSQgVDkVRFCUhVDgUJYmIyJ9E5LY4t90mImcd6HEUJdmocCiKoigJocKhKIqiJIQKh3LI47iIviki74pIo4j8QUTGiMjTIlIvIi+ISKFv+4+KyDoRqRGRJSIy3bfuaBFZ6ez3NyAj7LcuEJHVzr5viMicPpb5GhHZIiL7RWSRiIxzlouI/FJEKkSk1jmnWc66BSKy3inbLhH5Rp8umHLIo8KhKJZPAGcDRwAXAk8D/w2Mwj4nXwEQkSOAR4AbgSJgMfAvEUkTkTTgn8CDwAjg785xcfY9Brgf+CIwEvgdsEhE0hMpqIicAfwvcClQDGwH/uqsPgf4kHMeBcBlQJWz7g/AF40xucAs4D+J/K6iuKhwKIrlV8aYcmPMLuBVYJkxZpUxphV4Ajja2e4y4N/GmOeNMe3AHUAmcBIwH0gF7jTGtBtjHgPe9v3GNcDvjDHLjDGdxpgHgFZnv0S4ErjfGLPSKd+3gRNFZBLQDuQC0wAxxmwwxuxx9msHZohInjGm2hizMsHfVRRAhUNRXMp9n5sjfM9xPo/DtvABMMZ0ATuBEmfdLhM6cuh23+eJwNcdN1WNiNQA4539EiG8DA1Yq6LEGPMf4NfAb4ByEblXRPKcTT8BLAC2i8jLInJigr+rKIAKh6Ikym6sAAA2poCt/HcBe4ASZ5nLBN/nncD/GGMKfK8sY8wjB1iGbKzraxeAMeYuY8yxwEysy+qbzvK3jTELgdFYl9qjCf6uogAqHIqSKI8C54vImSKSCnwd6256A3gT6AC+IiIpIvJx4HjfvvcB14nICU4QO1tEzheR3ATL8BfgcyIy14mP/ATrWtsmIsc5x08FGoEWoNOJwVwpIvmOi60O6DyA66AcwqhwKEoCGGM2AVcBvwIqsYH0C40xbcaYNuDjwGeBamw85B++fZdj4xy/dtZvcbZNtAwvArcCj2OtnCnA5c7qPKxAVWPdWVXYOAzAp4BtIlIHXOech6IkjOhEToqiKEoiqMWhKIqiJIQKh6IoipIQKhyKoihKQqhwKIqiKAmRMtAFOBiMGjXKTJo0aaCLoSiKMqRYsWJFpTGmKHz5ISEckyZNYvny5QNdDEVRlCGFiGyPtFxdVYqiKEpCqHAoiqIoCaHCoSiKoiTEIRHjiER7eztlZWW0tLQMdFGSSkZGBqWlpaSmpg50URRFGSYcssJRVlZGbm4ukyZNInQw0+GDMYaqqirKysqYPHnyQBdHUZRhwiHrqmppaWHkyJHDVjQARISRI0cOe6tKUZSDyyErHMCwFg2XQ+EcFUU5uBzSwtEbdc3tVNRra11RFMWPCkcM6ls6qKxvS8qxa2pq+O1vf5vwfgsWLKCmpqb/C6QoihInKhyxEDAkZ76SaMLR2Rl7UrbFixdTUFCQlDIpiqLEQ1KFQ0TOFZFNIrJFRG6JsF5E5C5n/bsickzY+qCIrBKRp3zLRojI8yKy2XkvTFr5k3Vg4JZbbmHr1q3MnTuX4447jtNPP50rrriC2bNnA3DRRRdx7LHHMnPmTO69997u/SZNmkRlZSXbtm1j+vTpXHPNNcycOZNzzjmH5ubmJJZYURTFkrR0XBEJAr8BzgbKgLdFZJExZr1vs/OAqc7rBOBu593lq8AG7HSYLrcALxpjbnfE6Bbg5gMp6w//tY71u+t6LG/r6KK9q4vstMQv04xxeXz/wplR199+++2sXbuW1atXs2TJEs4//3zWrl3bnTZ7//33M2LECJqbmznuuOP4xCc+wciRI0OOsXnzZh555BHuu+8+Lr30Uh5//HGuukpnA1UUJbkk0+I4HthijHnfmYv5r8DCsG0WAn82lqVAgYgUA4hIKXA+8PsI+zzgfH4AuChJ5U+uyRHG8ccfH9LX4q677uKoo45i/vz57Ny5k82bN/fYZ/LkycydOxeAY489lm3bth2k0iqKciiTzA6AJcBO3/cyQq2JaNuUAHuAO4FvAblh+4wxxuwBMMbsEZHRkX5cRK4FrgWYMGFCzIJGswz21DZT2dDG7JL8mPv3B9nZ2d2flyxZwgsvvMCbb75JVlYWp512WsS+GOnp6d2fg8GguqoURTkoJNPiiNReD480R9xGRC4AKowxK/r648aYe40x84wx84qKegwnP+Dk5uZSX18fcV1tbS2FhYVkZWWxceNGli5depBLpyiKEp1kWhxlwHjf91Jgd5zbXAx8VEQWABlAnog8ZIy5CigXkWLH2igGKpJ1AmLTqpLCyJEjOfnkk5k1axaZmZmMGTOme925557LPffcw5w5czjyyCOZP39+cgqhKIrSB8SY5NSMIpICvAecCewC3gauMMas821zPnADsADrxrrLGHN82HFOA75hjLnA+f4zoMoXHB9hjPlWrLLMmzfPhE/ktGHDBqZPnx7zHPbWtlBR38Kc0oJez3cwE8+5KoqihCMiK4wx88KXJ83iMMZ0iMgNwLNAELjfGLNORK5z1t8DLMaKxhagCfhcHIe+HXhURK4GdgCXJKP8AO5oHcYYHbpDURTFIamj4xpjFmPFwb/sHt9nA1zfyzGWAEt836uwVoyiKIoyAGjP8Ri4NkaSwhyKoihDEhWOWKhyKIqi9ECFIwaqG4qiKD1R4YiJSoeiKEo4KhxxMBhkIycnZ6CLoCiKAqhwxETU4FAURelBUtNxlejcfPPNTJw4kS996UsA/OAHP0BEeOWVV6iurqa9vZ3bbruNhQvDx4VUFEUZWFQ4AJ6+Bfau6bE4v7OLjI4uAulBEh4qd+xsOO/2qKsvv/xybrzxxm7hePTRR3nmmWe46aabyMvLo7Kykvnz5/PRj35UOx8qijKoUOEYII4++mgqKirYvXs3+/bto7CwkOLiYm666SZeeeUVAoEAu3btory8nLFjxw50cRVFUbpR4YColkF9Yytl1c1MG5tHWkr/h4MuvvhiHnvsMfbu3cvll1/Oww8/zL59+1ixYgWpqalMmjQp4nDqiqIoA4kKR0ySGx2//PLLueaaa6isrOTll1/m0UcfZfTo0aSmpvLSSy+xffv2pPyuoijKgaDCMYDMnDmT+vp6SkpKKC4u5sorr+TCCy9k3rx5zJ07l2nTpg10ERVFUXqgwhGDbnsjiem4a9Z4QflRo0bx5ptvRtyuoaEheYVQFEVJAO3HEQNNZlIURemJCkccaP8/RVEUj0NaOJI1++Fg4lA4R0VRDi6HrHBkZGRQVVUVs2I9GDGOZGKMoaqqioyMjIEuiqIow4hDNjheWlpKWVkZ+/bti7pNc1snVY1tUJNOanBoamxGRgalpaUDXQxFUYYRh6xwpKamMnny5JjbPL++nGsWLeepL5/C9JL8g1QyRVGUwc3QbEYfJAKOr6qza4j6qhRFUZKACkcMAo5ydA3VIIeiKEoSUOGIQUBUOBRFUcJR4YhBsFs4BrggiqIogwgVjhhojENRFKUnKhwx0BiHoihKT1Q4YtAd4+ga4IIoiqIMIlQ4YuD2+VOLQ1EUxUOFIwbuXN+dKhyKoijdqHDEwM2q0oECFUVRPFQ4YuDGODo1xqEoitKNCkcM3ImcNMahKIriocIRg2BAXVWKoijhqHDEQF1ViqIoPVHhiIGm4yqKovREhSMGooMcKoqi9ECFIwZBFQ5FUZQeqHDEQGMciqIoPUmqcIjIuSKySUS2iMgtEdaLiNzlrH9XRI5xlmeIyFsi8o6IrBORH/r2+YGI7BKR1c5rQbLKH9AYh6IoSg+SNue4iASB3wBnA2XA2yKyyBiz3rfZecBU53UCcLfz3gqcYYxpEJFU4DURedoYs9TZ75fGmDuSVXYXb5BDFQ5FURSXZFocxwNbjDHvG2PagL8CC8O2WQj82ViWAgUiUux8b3C2SXVeB732DgZ0IidFUZRwkikcJcBO3/cyZ1lc24hIUERWAxXA88aYZb7tbnBcW/eLSGGkHxeRa0VkuYgs37dvX59OwO05roMcKoqieCRTOCTCsvAaOOo2xphOY8xcoBQ4XkRmOevvBqYAc4E9wM8j/bgx5l5jzDxjzLyioqLES4/nqtKe44qiKB7JFI4yYLzveymwO9FtjDE1wBLgXOd7uSMqXcB9WJdYUghqjENRFKUHyRSOt4GpIjJZRNKAy4FFYdssAj7tZFfNB2qNMXtEpEhECgBEJBM4C9jofC/27f8xYG2yTqA7HVd1Q1EUpZukZVUZYzpE5AbgWSAI3G+MWSci1znr7wEWAwuALUAT8Dln92LgASczKwA8aox5yln3UxGZi3VpbQO+mKxzcNNx1VWlKIrikTThADDGLMaKg3/ZPb7PBrg+wn7vAkdHOean+rmYUfE6AKpwKIqiuGjP8RhoOq6iKEpPVDhioBM5KYqi9ESFIwaaVaUoitITFY4YeFlVKhyKoiguKhwxCGiMQ1EUpQcqHL0QEHVVKYqi+FHh6IWAiAbHFUVRfKhw9EIgIOqqUhRF8aHC0QsB0XRcRVEUPyocvRAU0RiHoiiKDxWOXgiIaDquoiiKDxWOXggEBNUNRVEUDxWOXgiIDnKoKIriR4WjF4IBTcdVFEXxo8LRC6L9OBRFUUJQ4egFm1U10KVQFEUZPKhw9EJAdJBDRVEUPyocvaCuKkVRlFBUOHohGNAOgIqiKH5UOHrBDjky0KVQFEUZPKhw9EJA03EVRVFCUOHoBR1WXVEUJRQVjl7QdFxFUZRQVDh6QTQdV1EUJQQVjl4IBgSjwqEoitKNCkcvBER0kENFURQfKhy9oFPHKoqihKLC0Qs6dayiKEooKhy9oOm4iqIooahw9EJQYxyKoighqHD0guiQI4qiKCGocPSCpuMqiqKEosLRC5qOqyiKEooKRy9oOq6iKEooKhy9oOm4iqIooahw9EJQ03EVRVFCiEs4ROSrIpInlj+IyEoROSfZhRsMiAidOjquoihKN/FaHJ83xtQB5wBFwOeA23vbSUTOFZFNIrJFRG6JsF5E5C5n/bsicoyzPENE3hKRd0RknYj80LfPCBF5XkQ2O++FcZ5DnwgG0KwqRVEUH/EKhzjvC4A/GmPe8S2LvINIEPgNcB4wA/ikiMwI2+w8YKrzuha421neCpxhjDkKmAucKyLznXW3AC8aY6YCLzrfk4ZmVSmKooQSr3CsEJHnsMLxrIjkAr05cI4Hthhj3jfGtAF/BRaGbbMQ+LOxLAUKRKTY+d7gbJPqvIxvnweczw8AF8V5Dn1Cp45VFEUJJV7huBrbsj/OGNOErcg/18s+JcBO3/cyZ1lc24hIUERWAxXA88aYZc42Y4wxewCc99GRflxErhWR5SKyfN++fb0UNTp2rKo+764oijLsiFc4TgQ2GWNqROQq4LtAbS/7RHJlhVfBUbcxxnQaY+YCpcDxIjIrzrLi7H+vMWaeMWZeUVFRIruGoOm4iqIoocQrHHcDTSJyFPAtYDvw5172KQPG+76XArsT3cYYUwMsAc51FpWLSDGA814R5zn0iWBA6OhU4VAURXGJVzg6jE0tWgj8P2PM/wNye9nnbWCqiEwWkTTgcmBR2DaLgE872VXzgVpjzB4RKRKRAgARyQTOAjb69vmM8/kzwJNxnkOfyMtIpa6lPZk/oSiKMqRIiXO7ehH5NvAp4FQnYyo11g7GmA4RuQF4FggC9xtj1onIdc76e4DF2ID7FqAJL25SDDzg/E4AeNQY85Sz7nbgURG5GtgBXBLnOfSJgqxU6ls66OjsIiWo/SUVRVHiFY7LgCuw/Tn2isgE4Ge97WSMWYwVB/+ye3yfDXB9hP3eBY6Ocswq4Mw4y33AFGalAVDT3M6onPSD9bOKoiiDlria0MaYvcDDQL6IXAC0GGN6i3EMCwqyrGFV09Q2wCVRFEUZHMQ75MilwFtYt9ClwDIRuTiZBRssFDgWR3WTxjkURVEgflfVd7B9OCoARKQIeAF4LFkFGywUOhZHdaNaHIqiKBB/VlXAFQ2HqgT2HdJ0xzjU4lAURQHitzieEZFngUec75cRFvQernTHOJrjtDga9kH2KDtZuaIoyjAk3uD4N4F7gTnAUcC9xpibk1mwwUJOegopAYkvxrF7NdxxOLzzSK+bKoqiDFXitTgwxjwOPJ7EsgxKRISCrLT4sqrK19r3D16FuVckt2CKoigDREzhEJF6eo4vBXaMKWOMyUtKqQYZhVmpVDfGYXF0ddj3QDC5BVIURRlAYgqHMaa3YUUOCQqz0qiOx+LoFo64DTlFUZQhxyGRGXWgFGSlsj+edNyuTvuuwqEoyjBGhSMOxhVksqe2pfcpZF2LIxhzGC9FUZQhjQpHHJQWZtLQ2kFtcy9xDlc4RC+roijDF63h4qCkIBOAsurm2Buqq0pRlEMAFY44KC3MAlQ4FEVRQIUjLkoKrcWxq6Y34XBcWSociqIMY1Q44qAwK5WstCC7erU4tB+HoijDHxWOOBARSgoyKatuir2hKxyuy0pRFGUYosIRJxNGZLG9qhfh6HD6ergCoiiKMgxR4YiTI8fmsnVfA60dMayJjhb7rsKhKMowRoUjTqYV59HRZdha0Rh9o45W+67CoSjKMEaFI05mFNthuzbsqYu+UbfFoTEORVGGLyoccTJpZDZpKQE27o1HOHS2QEVRhi8qHHGSEgwwbWwu75bVRt9IYxyKohwCqHAkwIlTRrJyRzX1LVEsCo1xKIpyCKDCkQCnHzma9k7D61uqIm+gMQ5FUQ4BVDjiYd0TsPRujp1YSG56Cv/ZWB55O7U4FEU5BFDhiId3/w7L7yc1GOCsGWN4eu1eWtojWBWuxdGpwXFFUYYvKhzx0NnWbU1ccmwp9S0dPLtur7OuA/6nGF6/Sy0ORVEOCVQ44qGz1YoHMP+wkYzLz+DpNY5wtNVDexM8fyu0O4MgaoxDUZRhjApHPHS2d7uhAgHh+MkjWLWz2q7r8M1F3lRp39XiUBRlGKPCEQ+dbSECcdT4AsrrWtlT2+zFNfyocCiKMoxR4YiHjjbrrnKYO74AgNU7arpdWCGocCiKMoxR4YiHzjYrBk7sYsa4PNKCAd7eVq0Wh6IohxwqHPHgWhVO1lR6SpAzpo3msRU7aWxy5ujIK/G2H67C8cR18ModA10KRVEGGBWOeHCFw+eu+tLpU6hr6eA/a3bYBWNmedsPV+F45xH4z48HuhSKogwwKhzxEGZxAMwpLeDoCQW8uXmPXXD4md72w1U4FEVRUOGIjwjCAfDRo8ZRvr/Gfik9Dm5YAdMusJ0CFUVRhilJFQ4ROVdENonIFhG5JcJ6EZG7nPXvisgxzvLxIvKSiGwQkXUi8lXfPj8QkV0istp5LUjmOQBeKm5YBtX5s4vJEGd4kZQMGHU4BNPU4hgsGAO/nA0rHxzokijKsCJpwiEiQeA3wHnADOCTIjIjbLPzgKnO61rgbmd5B/B1Y8x0YD5wfdi+vzTGzHVei5N1Dt10WxyhGVSj8zKYUZQBgElJtwsDKaHCUbfbBpSNSXox+4QxUL19oEuRHDpaoXYH7N8a/z7NNbD/g/4vy7bX4d1H+/+4ijIAJNPiOB7YYox53xjTBvwVWBi2zULgz8ayFCgQkWJjzB5jzEoAY0w9sAEoYSDo6gTjDCHS0bPPxrzSLADWVzhurEBK6JAjG56yAeX6vckuad94/yW4ay7Ulg10SfqfdifjLczFGJNXfgYPXtT/ZfnTAvjHNf1/XEUZAJIpHCXATt/3MnpW/r1uIyKTgKOBZb7FNziurftFpDDSj4vItSKyXESW79u3r4+nQKh7qrNnBTR7jLU4Pv/wGp5cvQuCYRaHW3lF6ig4GGjYB6YLmqLMMTKUcccOS0Q4GiuhqTo55VGUYUIyhUMiLAv318TcRkRygMeBG40x7mTfdwNTgLnAHuDnkX7cGHOvMWaeMWZeUVFRgkX34a/wI3T2ywpakZg2biTf+Ps7VDV1hc45PtiHWu92w/UibIPV1RYL99onIhwdLZE7dSqK0k0yhaMMGO/7XgrsjncbEUnFisbDxph/uBsYY8qNMZ3GmC7gPqxLLHn4K/xIlatTKd316RPJSAmyobwpzOJwWr2D1eJwRS6CNRVCb9dhMNJt7SUiHK12+6EolIOB1nrY/uZAl0JJMskUjreBqSIyWUTSgMuBRWHbLAI+7WRXzQdqjTF7RESAPwAbjDG/8O8gIsW+rx8D1ibvFAhtrUaqgJz1+dlZLJhdzNb9LRi/cHRbHGGVbWs9NO3v58L2AVcQehM2vxXlVsiDnW5XVQIWRF+sFMVj9V/gT+dDa8NAl2TwU74e2obIsxRG0oTDGNMB3AA8iw1uP2qMWSci14nIdc5mi4H3gS1Y6+FLzvKTgU8BZ0RIu/2piKwRkXeB04GbknUOQJirKkJl0tlqU3FFuPS4Ulo6hdbWNr726Gpqm9t9c3SEpegu/ib87VPJK3e8xOuq6hyKwuEGxxOwkNz/WN1VfaNpv00mGSr3yEDR1gR3nzhkEyZSknlwJ1V2cdiye3yfDXB9hP1eI3L8A2PMwa1tQ1w0USyOoE3FPXbiCLKnjSOwpZN/rNzF8ZNGcHk0i6Nq6+AISHeGuao62601lDUi8nYwdFpJ7e61TzDGAcmzOIwBiXhrDw/aG+27Cm9sXGHdMTTdetpzvDc643BVuX04gGnjCkmlk3H5GfxnY0X0GEfjvsHxcLmC4LbKl/0OfnNCz+1CXFWNyS9Xf9CXdNxkWBz+3x/us0O693v7ILi3BzPuvRlMG9hy9BEVjt4IcVVFCY6nZHjfAykIhjOOHMVrWyqprq11jhOWVdVY6T1kA0l4cLx2JzRW9CxviKsqCeV+7Zew/Y3+PWZf0nE7+rBPb/j9/YM1SaK/cK3RwdAoGsy41ymYOrDl6CMqHL3RGSG1NmR9K6T4Wg2BIADnzyqiub2TjTttH5K2Vt++7c12rvJEHq5ktVTDx+FyK7lwcQhxVSXB4njhB/DH8/r3mIPF4mir9z4Pd+HodlVpckFM3GdILY5hSkhWVRwWh9OCOHFSASu/ezZTCq2Q/P2t97n96Y00tnZYawNs5RxP2mflZvjRCNj0TOLlf+K/YM1j0de7AzK659YWRTj6I6vqtTvh4Ut6Lvdfg1gujq3/gTuOiD9jp2OQxDj85R3u45ipxREf7Socw5u4guN+i8PJN+hspbD8TYoyuwB4a8te7nl5K5f+7k1aat3hRwy8ege8dV/sMlQ5Yy39++uJl3/DIvjglejrwy0OtyUULg79ERwvXwt73oleBoAdMdxVlZuhodzGh+KhT66qZFgch5Crqi9W3qGIWhzDmLfug0d9SVwRhaOlR4wDsNbBnz+KlK8D4IQJufz8kqNYv6eOX//Ll0mx8kFY+w9i4mbh1JVBcwLDYRhjH+RYMYnuSaocYYhmcfRHOm5Ha+QK2f9br9wRPX020X4ZfXJVJdniGO7C4VaIHYMgfjeYUeEYxlRvC60kI7k8OtsixjjCW8VXzBvLJ44t5ZZzp7G/Ype3oqkKWuuIib9irdgYX9ndspmu2A+x6zpxz80VjvB9+sNV1dHqiUJ9uX2BV1mPnw/bX4dVUYZBdyvzeIPziVocnR3e9UhajGOQDj3TX/SXxVG55cDLMphR4RjGZIaNn5iIxdFaH7qdU2F88cNTuO3ssd7ytgYaavezZFNF5DJseSFUWBJpybkPcay4QZ+C430Ujk7H4jAGfn6Effl/6+ir7Hs0V5RbmScsHC3w8s9CRwBuiPAbfrHoT+EIsTiGuXD0R4xj59vw62Ntz+rhSrtmVQ1f/J3gAilxxjicG6GHcHguikBTZeiq5hpu+Msqyuu8h80YY8f8eegT8MIPvY0TyY/vzqmP5aoKG3KkO8YRLhw+F8uBWByYnu4a97qmZdlrGa283fGHBIWjsxVeus0OcQ+w7gm443BbQUU6fvjnA+Vgxjiqtg7sUDbt/SAcDY4lGm8sayji3hNqcQxDskZ6n9NyYnQAjGBxtEW2OIAeD0SutNDe2cllv3uTRe/s5s9vbuPoHz/PW287sRC/0NTuhCW3Q1dX7+XvbnHHIRwdYa6qcHGINFR8ori/URXmhnDLl5Jpr2W0SjthiyOsnO65uVlmNWETWA0Hi+PhS+Cl/0nub8SiP1xV3XGmYZyZlYzRF/a/n5xU+QiocMQi02dxpOfF6ADo9RzvjnG0hMUtYghHgC7+dOVM0lICfOWRVXzvyXU0t3WyfP17dgPx/U3rnoAl/wvVccxSF4+rqstncXT5xhiK5arq6wB2bmWye3VYOZ3ypWY4wtGLxRGv1RV+Du5D5c546P/fIEw4+tPi8DUiupIsHM37oSGK2/NAaKntfcyvrs7ExT0Sh4RwOPdif90PxsDvPtx7hmY/kdSxqoY8fosjPSdGB0C/cESLcfgeusZ9VpSaPZfCiSWpPP3VD/HSxgoKslLp7DKsv/+PkAKdkkLQOPu741vFavWveQxSsyC7qPdt/TEOf2slWj+OlAxo6ONshu7127PavqfnOctdiyMjPosjXldV+P/lnp9raYS3zkJcVcmyOJLsqmpv6Xnv9Qf3nAJHfxo+/M0Yv+27zw5EePuSRh2Jri5Y9WeY+XHIyDuwY/U3bj+O/rJAO1ptLDTMDZ4sVDhi4Y9xpOfG1wEwLuGohILxIcJBSx3BvHGcNWNM96Ki4k7YB8Eub9+G6nJygNamBsLayx6v32mF6VSn30esStDfATCWcLg3eOHkvk8z616D3avse0o6/PN6ryJPybBWR9QYRz+4qjo7vGSDtkbbSm6ogLzi5Fkc/sEsk+mqMsaeQ38LR3sL1OywWYax8LtfDkR4+8viWPcP+NdXoWYnnHnrgR2rP1n7OOxynoH+6hB6kPvPqKsqFn5XVWahNdfDCQ+Ou1kSbWHuHLfCMMZaHPnjQ9f7M6c2Pw8NFRyW6glLl9jjZnbY7X7z/BoeeGMb+xvbaO8Mi3e0NdqHrjs4HofF0dkWWuZoHQBHOMLRl4mO3IrArYDaW+D9JbDtVfs9NdOKSb/FOMJdVQ2hLr62Ruv6u2uu7R+TrBhH/R7IyLefk2lxdLYBpv+Fw3WtttTE3s4/+GV/xDgOdKBEt+NrWvaBHae/eezzUGH7d/Xb/XCQ55FR4YiFv3/GiCk2+OQGpZ+8Ad75q3XhpGZ527kxjmgWR3O1bWUUTAhd7wpHRxv85TJ4+w82EO4eNiMHJEBQbIW9bvtevr9oHcf8+HmmfudpLr3nTepanMq9tcFWmomm44YIRxRXVeEku10kEe2NDt81AEfcfJVNSrrjqopS3kR7dbc3hVqDbY1Qtzv0e80Oe7zasuRZHPV7vP87mRaHW/7wRks8LPk/+OWsyOu6haOX/7y/LI72frI4ypysucGcudRf90N/uffiRF1V8TJqqq2I6nbZynbVg15HtcwCbzvXVdUjOO5Umu44VeEWh7t9a72dCKduV2gQPSUTUtu7K4U7LppK2bhTeH1rJXXN7dz7yvucd+erTB2Tw73N9ZjUXN7btofZYOMwXV0QcNoJbU3wzM1w5vc9U3nfJnjmv73fi+WqAls+/3nHg1sRuL/Z1R7q/+/OqoomHG5LNM6MlPYW29JvcCvUxtDKr63B+1/qyyPPFX+gGAP1e2HsHNi7JrnC4Va4fbE4lvzEvkeaLyRui8N3z/SLqyqOSrCx0iaPhM8f09YIFet7lmugCc+G7DdXVR9muzwA1OKIl1FT7Xvle7D+n/azM4FTtxsCek/HdR/CaBaH+x6esupmHDkUpnQwuzSf6z48hW+dO427rzqW6cW57KttJq2rmX3Vtfztzc3d219014v8/LlNtn/I3jWw8s/WTdRdce4OHSeqo9kOKrjqodDyj3CEo9bX+z0ejImczuyvrLuzqnoTjjgeDmNs5eHvxNnWEOoSbG/yvjeUJ25xdHbAc7d6PeAj0bTfXuNuiyOJrqoOn3DEk64diUjpnPFaHCGuqoMU43j8C/DUjT2XN/j+k8E0G2H4M9Bf90O0eX+ShFoc8TLK6eVcuRk2/tt+Ns7DmVHgbed2AAyn2+JwhSPM4vjXV23QeN7V9nt4IDIlw1ocLmGtqLNnjOHsGWNsC/5/YVRaJ5fPGgmOK7Wsoopf7W1j9c4a7jy2kpFAR30FKdFawO3N8MavYO9a26Pb76qCEDcaYAPM2UXRZ7eL54buDo734qqKpyJo2m8rshFTYJ8zTEurz8WWWRhaSTbshbwS+1mC8VVa+zbCG3fBiMNg3ucib1O/x74XTLTvB0M4MPbc03MTP0bzfptB6MdN743bVSUHmFWVgHDU74m8nd/qGkwWR/h16TdX1cEdlVgtjnjJLrKWReV71q0DXmXqtzj8n/2EC0ducU+RWfEn74Z3KxwX1//v4t4olZtDB0l0KsMM2phV5Pl27/3kTH68cCYrtlfzo8eWAfD0srW0tvV8wE16nj1+9TY7qVNrvVf+/FJbsdb5LI7aMvj5NGvBRCP8gUmPkB6ZEqfFEc/Dsd8ZUXjMDG9ZW6PnEswZG/q9ocI7bka+V95HP21btWAHpNy1wjuem/oYq4dzt3A4Fkcyh1X3X5e+BsgjDaLpuldb6mJbMu49mVlwgBZHAm6XtsbIVlJLmGU5WAh/DvrrftDg+CDjaxvhv96wLemRU6HsrZ7BR7+vP9zX6tLtqqoExGZspWaGbpOS0XPAw9xib12qXzich2vZ7+BJ37Tt/kEKfQ/MMcUZfOrESTxyzXwOy7MPf93+vdQ29Hyo9pOHaa23gWOA/R94abspGZA7Fup8wlZbZuMy7vaRCL+hw69TSoa9xrH6cbgt0XhakK6rb3S4cNRa0UrPtd/9rqp2v3A4n9c/CWv+bl1fi78Jr/8/73humm2sDnfhwpFMi8NvqfW1k2ak4Uq6hdHEHpDTrcAzR/T8D42JPxMvEYujtT7y/TBoLY6wc+p3i0OFY3CQVwxjZtrPo46w8QGAkYd72/itDL9PfdKpMPsSGxh1rZPGCltpBlNCLQiwrpLwlmLeOPuekm6Dxy7ujdJUaT+7MwS6D6/pCnUtOA/PUeML+OopYwH4xJEZFKSFPsw1aWN5vzmLym3rultDz7z6BlvLazASpL3LQM6Y0E6A7u/4BbW+3A6R7lYW4b7dzAjC4b53NMOqh3smGCQyOm7VVmsZuS5GsO6blhorHGnZocJRXx7Z4nBprLTlcobJB7xKNpbF4Qpsfql9T0Q4mvbb7L14h5E4EIvDjddFtDh8whjLXeWWM2tkzwpy0Zfh75+NryyJtJ7bGqMIh/O/pmT2zeJorOx5//UH7v8/YyEcuaD/YxwqHIMQN0AOMHa299kvHMFUzw0zZiZ84vdO50FHOGp3eWKQmgGpvhzzlprELQ638nIfWn8l4+9g6H+4nEolo62aNPG5HqZfSP63N5KVU0BRpxdcXP3OKl5Yu5OWriAzv/csq6rTaazaRU1TG29v209DjePK8LdyNyyC//wYXv4p3Dm759g8/l757vmBFcjmanjyS7aPhZ9EXFVVW2wrP9xf7/apcIWjxR8cdx66jDzY/hpsedHbz00cqNrqXePGOFxVjRU2BubGGzoTcE1se81m7u15N77tQ4QjwUrPvf7RXFXiDqUTSzic/z97VM841b6N1q0aD/H21+lotQ2y9gjC6gpnzui+WRyPfBKe/Xbi+/WGe26zLraxMc2qOgTwt17HzrHvwfSeLifX6nCXB1O9lkXdLshzWp8pmbYCu2UHzL/ePrT+BzM1y3OD9bA4woXDeWj9wuF3O3T0FA6aKkNbPJkjEBFmTBjdvcgEUvjGcamcdcQIAimpfPrEiWxpyaW1ehdzf/Q8l9zzJj9fZGMmb27YxkNLt/PM2r1U7XNa2ttetS6s8Mo13FXliqL/WvqFz5+VFU9FsH+rtQrdlrRL3W4rDGnZTpZVvbe9m5Lqxp4e+ri33/svuwXx5kSJx1XVXGPvh0AQkMRamOGZduG8/DP44/meVRehcRA37rA5zZFcVZVeMkcs4WittwKUlt2zAmup65lpGI14W8/RRnIG75rljOmbcNTtTjxzMB7cvkwp6TYDs7/7cSQyTfIBoMKRCK7FkZplWwsQORjuLnMr+mCaV2HUlkG+k72T6jxkGfnWlWG6QofzyCjwOhf2sDicFnxzuMXhezj9wtEeoTXaGCYcTmUu7m8G05BxR5NS/QFTRqaTnpbOdy+YwUWnHsMIaeB75x3OQwvzOW6UbTV9sLuc7/5zLdc9tIIn37QunepddqDGZ5auDr1GPSwO51r5x/3yt379lUhvFUFjFVRsgLGzenb+qtsdanG01kG67z8cdQS8/1LPY37wsve53HFXusLRGEM4Wmo88fffB/HgVv7RROCl26xltP5J+91/jaLt09UFO5b1XG4cV2dzTc91bY1ev6MHLrBzxESircGOIh2p939LbQJzxcfZ0bM7ntfSM2jfUmevd2Zh31xV4anbvdFSC+892/t27jmlpNsGZX8NctihrqrBS+Fka7Lnj/esikjC4Va8qX7hcDq7tdR4/u6UTPuggdcC96fhZhZ6x0jJiBLjcCqviBZHlXd8/8PjVirN+wFfjMM9J7ciHH8CFB1pM8k627or4dR86z77/JHtnPL8RZzX/C8ALp5VwKvfOp1/fOkkzphoM73z2+yxlq3ZEHKJnnk/rAJ1BcN/jq5w1IWlXEYb5HD/B9a6Wfu4dQHMvsQbbmK0E6dqa/BiHE2Vdrv5/wXXvgy3VsF/vQnn/7znsau2AGLLt2+Tjd+ULbfrWmqtSC/5P29++O5zqPHStd37IF5cN1q0Vr47iOXSu+27/7pE6z2+8V9w/zmh2WHQ04J1McYey3WvArz0v5GP3dpgXYORMuNa6+Lv0R5vVpVfiMLFobXeugdTM/tmcbQ3JRbjeOev8JdLbaMlFq5FEEy3lq3p8uKTB4K6qgYxKWnW/VE4yWtFRuo97Vb24a4qN4XVdVUVjPeybdxgsTvkN9iKPMUnHOEWR1uTb5iJKDEO97gdLbZS+NnhXgfGcFw/fOnx9n3hr6FouhWS+nJvHK4cG1xnz2roakeclllaZxPjR2RxzIRCJmVZYQg4Q6QsmBzav2N5Rej3HfWGr/1tNS9/4D2sVfvK6Vj3L/jFtNBWbrSK4Mnr4Z9fsllQY2bbGFNqBtxaCR/xzVGRkR8aW8oeBePm2oSFYArM+zxc8idvvRtnyi6CwomwY6mN39T6ssiW329dXb86JtR1FWJxJNjC7HZVRbAe2po895+bzRZicUSp9LY7c7xseRFeu9O21N256aFnjKO9GTChwlE0LfKx2xogLbdnZlxHmz1+Zxu9Ds0O8WdVxRqUs1s4shK3ODrabFkTsjicbZt6EQ73urgWB/SPu6pbOLQD4ODk4j/Ym9H90yNaHK5wOJZHwBEO1w3luqo++ivPP+1aHP7JhTILfBZHeui8HO3NoTdpt3CEDeGdVWgruH/+F5xyU+xArmudnHYLnPRlGwsYPd0u27vGswpynRF8964N3d//22EV0HEjO8Dnhfvmx06CJ7y5A3bUdfHK5kqCzdV82Lm0m7btJLP1MY4Gb0Td9LzoHQRrdtoytDXC8dd4y4OpoZ3h3BhH9/cI/6HbGRDgmM/Ay7dbC6V4ju1R7+IOj7/5OW9Z5WYblIUwiyP1wGMcblqre58UTrbC0dUZX4zDHb/p5Z9aEZt6tud2hQjC4VS6rngCtEaxgFrrfRZHszd8ib/8bQ2QEiVl3SXerCq/W7aHxVFn75XUPmRVucH2RCyO7n1qYm/XLRwZXh3S1Q5kRN0lvt/3WRyRho3pZ9TiSJSxs2HkFK8y8Pcad3EzVNwbw3VRuBaH66pKzbTTpYLnJurq8FrD4a6q8Kwqv3C4FUV46qY/lvDand7nSOV2K9NA0Ju/wBWO+t1evMC1OMrDhMNfQYS7PPxDQADpeUUh30+ZPp7l3z2La8/w+l2UZLSwa48Nsj+y9H0AKjoyaW9t4uO/fZ0fLLITXt37yla+/881mIZyW4l3tnrlDj838GIcXmHogb+F7c6Fbrq8WJSL+1/uXOYdx+0YaEyEGEciFkeEGMczt8CPCq1bDmDCiTY+0VjpVUrZoyO3fDtaYa+ToeVaPhUbQgWnoTy0v4XbGEjPhc88ZS3QpgiZV+62aTl2W9PlldvvaosmaB1t8Mavrasn3uy5Xi2OvL65qtzjdjTH/3+5WYORYkR+/BZHIAkWB+agzGuvwtFX0nNtvCOWxeH+mUG/xSGhrTcXf5aRWxmFWxzhMQ5/Bkxbozc+U8hx/UFoX4Xg74fiEmn46dxiL3jsCmF2kbV+3ErIpTW6xdEj88h/vhLstmamjhvVvXh8RitH5lv/7+xce14NkkMq7aQHDQ+8uY15tz3PTxZv5IllGxBfRskTO3N48M1tbNrrVFR+CyI9z7OuIPLQHDlj7DmmZFqX4pnfh0/+tefglJmFnjvw8LPsu5um29ZoGwJ+i2P1w7D8jz1/z8XvauiueH2CvOwe++4O4Ddhvn1v2GsrukCqFb1I42ftXeNYob57YutLtkxgMwWrP/B+wz0HsNbz5FNh1OHR3TFujMO9f92GUvjAkpH453Xw3Hesm9F9blrrbUpyNEJiHGH3fWtdqKsqvPPhjqXw+DWRe8K3RYgH9ka8Fken31XlOHz6o6L3x7cOQmaVCkdfEYGTv2I78oTTQzicbJq9a6y14lbAftLzPVeUP+4RKasqI9+xOHzC8e+vwwMX9nww/S1nP/4+KSd9GY44D8bPj3ye7rAd7gCOwRQbpwkP2rq/3dXV8wFyLQ7XGnMrr5RM+4B3x3I8cQy01DA1zQrQrBz7AB82wVbcj3x6Jn/4zDwuPGoc/zh2Ha9MC+3zcesb7dz65Dqu/P1SLr77Db7wt01UzrTjSVW3Gl7c7fPSRpodLphqxcMt56lfgyPP84Qja5TtwHXOj2H2xXbZxJPsu1uxutfHbVy4Ftsrd/T8PYDtb8BtRd5YaP4Rk8PZvcoKoNszvn6vbc2mZtqe/fV7bQveH6x3Px+5wFu2+iF47rv280lfgYmnwFv3euvdSrQ7iWNkZOForPQsDlc4XNdsiMURQTjq9tiEBnASM5xKvrka/nR+9BEJYk0D0FJn/1f3WQy3Xtb8HdY8Gjkjzn/ceKcPSNTiCKZ790N/ZFaFjEzcaqdn7o+gexRUOA6Es34Ah3245/LpH7XvE06w78FU25LcucxmKkUiEPCC5um58LF7Ye6VoR3j3Eo1a5RtRfmFo6vd+q9bG0JdL7nj4IJfwqcX2WO5mTh+q2fMbLjir6GuMD8lx/Zc5o6S68etFFrrQt054D2gbtnS86ylkZYFx37WVsruebq0N3pjTrmt15J59n3XCs6YNobbz5/EMev+h4IPFnfvZvJKuO2yk/jFpUfR0WWoaW5n9c5aznj3LH4S+CIn/yufq19O559pF9Auady3uoVfPv8eG/bUsa2yka4up+LKK7ExIj9upVg0DT75CBQfZa2R074NR33SNgC6x3aqse+uq8oV3royzwL74FUbm+ls93pW73TSZbtdVb70aZd9G+1/mOu4Dev32sojJd0uq3zPtuBX+KwbtwI+/lo4/GwvCcIlLcuej99acStR1xp1hcPfgl/9CPxsiu1cmZ7bUzhCYhz18OovYMO/vGX+kaDd5BD/OG7R+snEGxyPtN6Nz/nnZ4l03GgB8pqd8OvjvPJGSy4IJ+muKuz1vPc0eOeRAz9uFDQ4ngwO+zB8r9qb/yKYZk3JjmYYf3z0/T52D/xpgY2jHHWZXeaPcbgtsexRdnTaxn2A2Aqpq922qqo/sA+3e8PnFXtW0VdW2ZbW898LfTgiWUB+So+z7+4os2CFw9+3QYK2ou/qityJzCUj35Y7NdOxorLh7B9668M7U7q4FsvkD9mpcbe9bvddEpYampKJjJ7BRUdb19T5c4pJCwaoqG/l/57eSG3wKr5SlM3YvAzueTmP/666gqYlFYhU8P9etD2bR+emc+m88Zxz2Beob2wibdt+5o4vYNWOGoo6RzAZMAUT6A4/pufYhAKA7JFejMNtfbquKn9LfddKmHqO7RchQfjSm945uq1c9z/c/jo89Ak4+lPe/vs/sPGNHCdRwbU4UjKtoLjuiqr3vX1qttn4VPEcuOoxO4Cjn9RMm/jQ3gh/u8q64aZ+xK7rjsWNsDGVxd+0VljeOFj5gHeMtBz7GxKIbHE018CS2+Gw02D6hXaZOytjarYX9M8s8BI5mvZ7U/76XZx+y8B/Pxvjuarccrc3QVeBjcuNne0NHRM+mKi7rUu0APme1Vacd62wmXbu71esg42LYdqCnvs8fg1setp+7s+sqv/c5s2iCc65GZsu7sbn+hkVjmQR8Blz/k5o0SwOgEknw7fLQlNF/X1CujOwRlrXV+V71v/e2uBV1uXrYeKJ3sPotyzyxllrBWxrODXbVhK9CYcrdn5z383EySy0ray8Epu91dbgtbrS83tm4GTk2XMScYZcCRMKv8XhUjDRq1CyRsC4Y+y0oBufsi3G/PHeMO9XPe5lrQHpKXaojDF5Gfzisrkhh73o6BKMMbR2dLGvvpXl2/fT1tHFc+vK+e2SLfza5AF58MabBAS6DKTQwdsZefxqZRppGRtJSwmwdGsVnz15EmdMG0161ihaasrJdK8xeBaHv5LavdL2kQFbEe9401vntoJdi8N02XRkd5w0d5/skTZFPGukM7y4Y3G4YgKexQbW4vDPA3Pu7dYCffv39ntqlpf4sOlpm7E16VT73e+qAnj7Plsxn/V92/ruvuA51pWZO84X4/BVvtvfsKJWt8vulzXSimAgBUqO8RonGQWecDRXW/fZKz+Db27xZtmMZnG0N9nYUrjFsWER/P0z9h5xM7IiCYdfkCJZHJ0dnsi7+7tis/5J2PAUfLfCi2G4bH7W+91gmmeBHoirqqszdOBN8IZ2CY9B9iMqHAcD90bMK4FRR8beNjxQ6/rf03Kg6Aj7II+dDZsWw553bE9nN1UV7E1YMs+bbzk8EF98lH0vPc4+xLWNvU+tGSlO4s4EOPFk79ze+p2tEP79DbtsxCRbRjdlFbxMF3A6QGaFHjclgsUx+VRYtd1bf9hp8MpP7feL/wiTToE7nJjNxJMSSkUUETJSg4wfkcX4EbYslx03gT21zeyqbqYoN52X39tHeV0Ls0vyqWps44eb/sLeJmHpy1ttCCg3gy89vJKUgPBglnBix2vU/mgCy8ZfzTnAExsa+XB+G91t5YwC+5+NO8YryMvO+Uw40QpHV1fP2EZDuV3viozbCMgtthaHK8b+/3z/+7ZyCQStW8Vv8eaNsy62buHI9NKIuzqsGLtl8LuqXDY/B6d+3WbcubgCk19iXSXtTaH3vJvKXLsT7pwFE06yVk7BBHsPuS1nf/+o5mqbDNC8314D935srbfWmum051m2HMbMsgF/gLFH+YapafI6PW54yjt23R6b3t3e5FkzfkEKtzi2vW69AhOceJYr8v6Auum0opfnT2Gu9yyvYLr9r9znLprFsWOpjYdd9mB0S9ydkRSs66ur3XP9la+zIhcuYP2ACsfBwG1ZXvJAqCUSD6NnwGUPw+FnWsvgs0/Bu4/addUf2EDnB6+G7lM8x/vsb32CHYbjxrXWD73yz/YBDsRxG3zmqdC51V2LI78Uzvs/ePfvVjhe+6VtTYPtrb3nHdthsnm/vbH9Kcgp6aHHBK816TJ+vldBpuVat8ApN3rT+M5YGNq/pZ/y14vzMynOtw/rp08MzTa78oSJtHd28cAb25h/2EgOH53DotW7eWvbfnatzQKB/K5aOj94DQLw/ed3Uff882xzQkjLAkdRunkVS/Y8y5VAa+YY0ut20ZZWyDtNYzm6YSMpbQ2A8SoDsAJ84V3wG8d16MarxsyyFsLoad6w9y6dbfY/ziu11yt85kn/KMWpWZDra0R0tHgjGbj/k184ytfaVrw/nuU2fFxf/vonYdoFXm9y1xJ2K9Edb9jGzIjDvP5B/t8DKxxuy94/SGhbo3XbNpTbhsQrP7VjvtWV2Wtz2GmwzWlAtTd76ePuvDEZBfa4f1pgReUHtd5xXVrrrKUz5UzbYHv8aq/cYK/trpU9s7oayu21qdwM598ROu5VeLp+ZzvsfBtevQPO/rFtIIIVjS3Pw/pFnuva5b1nQ70Q4N0nVY7F0dFivRL+OWn6CQ2OHwyO/hTcvB3GH5f4viIw/YJQd5LrPgCbHRWefjfWJxwpEayJgvH2uG4LKzyQHYnJp0KpL0g+YrJtOblZRu4otO/+zVozX1llkwOC6V7qb0q6dUdMONF+T83qKRzu99mXwvwvwaUP2MoBoORoex3Ssm1P8Ev+ZIUmyZ2dIpEaDPCFUw9jVkk+GalBLj1uPHdcchSfONm79udmbwEJcPsVp3D96VO6l6/tKKWEfYxtWMdeU8jD9UcDsKklnyV7UklpqeahF94CoDXTWgBm3tXwrffZ2DGGLjeomj2KvbUt7D3ik9YluHNZqHC4sZWqrdYq6OrwZiJ08TdkUjN7NjRc15FrcYSPlPD6XaHf3e2mnuMt2/iUrcjdBkr4dAJ73rEWrP+3/Z3/mvd7LXv/BGJNVbbPip9dK2ylOvNjtqXd7apq8gLi1R/YxsjIKfa4riVSWwZ/udz2lXFZfr+NIbz2C+v6CXdtrX8S7ju9Z+ZXQ4VNAFj1kLX46ny9X91n0r0e1R/Y7LH3nrGjQq9/0lqc7v/47l9Dj73paTu8yUMXW0srnOptXoPAPw1AP6IWx8FAJPLQJH0lr9h2xNq3wbNmwLbIwXMj9YbbeuwtEyQSadlw3auecPj7Rcy72rYg80pteueWF2zq49g58KFvetud8Z2errncMfDFV+15ufEOt3VaPDd6eW5a7w3UN4CIb54Sad4PpcexYE4JC+YA81ZCexNXV2+Dvz3MmSyjdeKHmTfp4/DKM0zNbiZ97jx481FefuN1rkqDfQ2tlArcuayef7/3Clv3NbAsLZvRUsPKyiDXv/g6Ta0dLB89h9SKd2nt7CI9u8hWztPOt+6ixd90rBOxQ6tEIzXLGcnXZ+VUbLTuQdcSzB9vW/KnfgP+dqW9B3PG2v+qZnvY6AM3wO2OhVM4yXHX1Nje6v6sKrDl8gtK0RGwc6n93FzdUzje/r1NzjjxBm/QyYx8JyPNeI0Ttzz73gtNvS2caF16/nTlRV/2XGmBVGvJ7ttor9vWJZ5bNlpKsp+Gcns9Oprtb/gtDnfEZrcxuPEp2/g75SZrsT/6abjoHi/Gs/Ulr4/Mqz+HF3/k7V/9gXV5nf9zW85FN9h1k06217hmW+xy9pGkWhwicq6IbBKRLSJyS4T1IiJ3OevfFZFjnOXjReQlEdkgIutE5Ku+fUaIyPMistl5Lww/7iHBlDPsu3+o9+M+D3OviN8dNusT9t0vPolQdKTndio60qaonniDHVwQbMtq1OEw/zr49i743OLQ/Y88z8YnwimeExokn3O5ddmdcF30suSX9HTDDARHXW7f3bnZ3f8JbAt37Gwr+g7pk09kzsnnA5BxzCc5Yqr9L356qm3TpafZ1umY0imML8zka2cdQXPQxr1++loVlQ2ttHZ28fX9FwFgdrzFFx5cxXcLf8rJq8/kv1NvZmtTBp073+au9Gv4W1khj60oo7mtk+1VjdQ2e/71rmAGze1dTsvfseJqd4R2DE1Jg08/aS1QN0YzdpZv+H+n8g84nWNnX2q/X3Cn10iY+TH7nj3aBqqvfsGmnrvHKJwEp3/XZgQVTbei4SYa1O22r+dutR0uz/Jl5E2/kO7MQ3e+nJGH25b9qofsd39fqdxiK3wu7qCVYCvljDybQHLu/9qg9tLfWtGIdM+GU7fLE4vyNaGjXrsxCTfG8d5zkD/BpnVf97ptYC35X98+xpuueutL1jV50petS23fe/Z6HfNpGHe09xtF0+z19Q+a2o8kzeIQkSDwG+Bs7ChFb4vIImPMet9m5wFTndcJwN3OewfwdWPMShHJBVaIyPPOvrcALxpjbnfE6Bbg5mSdx6Dl1K/Z7CnXjQP2IXLdNlc+1nOWvXCmnQ//vadngLov5IyG65dFXx8+oVIijDrcpqsOBaacYX3lT30Nlv/B+sbDcUUF7AOfnmNdmem53dlhhWv/BIEUir7wGKx6mCvOuokrHDFte78Ydu3gpotOomPEkXQZw+9fHcmSlqvYYsZTVt1EVdrhnDIrl9rWyVy9+wTKWusZkZpFxeO2df7jp9ZT29zO2LwMnHY9H7t3BXvrW3m1sIhUgLZGpKWa1kAG1bUtjM0PczGVzrND0I+ZZRNA9rzTMyvuwjttxZs9yrb+g+lOiq/Yxobb2x6sEI072vY7yh0DC38DD348dCTf2jJ44QfW/bPgjtDA7+FnW4FIyfRicKkZdrDLPe/Y3x5/vA3AF0wM/R/AxjPcWEx7k7WaRhxm/9P/3GbdUVPO7OnuCycl0yY/uBbw3rWhQ+64GWCuq6qjGaacbp/dsbPg5K96sZSJJ9t07Ir11lVcv9cOpzPqSMDYnvVux1P/tR8xxZ6ff9DUfiSZrqrjgS3GmPcBROSvwELALxwLgT8bYwywVEQKRKTYGLMH2ANgjKkXkQ1AibPvQuA0Z/8HgCUcisKRPcrLgz/nNtj0TKivf+rZ8R2nP0RD6cnMi6w/PFLnyWCKbRFmjfJSh/2t7SMX2Ky5mR+zld65PwnZPS3HuhhPmHEE5NiGw6lTi4DjOQ34QoTidHYZWto7eWLVLhpbO/jj69uYVZLH29uqWXHMD8ha8xDv7KojIzXAPU0TGRUoYhZbmBOo5oM64VO/fo2vnDmVkoIMjp0wgv1NbSzdNZpPAsuaxzHv3M/QOvEMVjSWUL9mD2t21XLTWUeQlpbtWSzZo6wrLD3HnpfrTnLJGgHXLgldllnoWRvBNG9k51O/3rMTqms5j5kRmmRRcqwVjokn2kp/26vWVTX9QnjqxtBjTDwZtr5oP5/8VW/5GbfCMzfbZJBCRzjGzPbcZAAf+Ymd2e+BC7zBJBEblI80LUC0uGWJL9tu/PE2+F7hWEYN5VbI3Pumrd4LfvuFY8IJ1u3muvv6mWQKRwngS/CmDGtN9LZNCY5oAIjIJOBowG3OjnGEBWPMHhEJi45173ctcC3AhAmDwIWRTE76sn0pg4fJH7KvaPzXG9HXnfl9O2TE/Osjr88sBIQesyjGIBgQstNTuGq+rfS++OEpGGNobOskJ/08yk7/Ig9XNZGdnsJLG6fwXnM7R+y6E8rfZ0ReDmkdAW7959qQY6Ywhh2Zn+fBZWNpevNFcjNSqW1+q3v9ut11TC/OpSgnnTOnj+G37V9kRE4GN3cZAtcu8aajjYX/HEdOtR3s8krglK95y2dfYt1rIw6zx/RP6wyOS+1+OOx0rwIvmBhqrbtM8gmHn+OvtUkkMz7qzQB50pdtcsp9p9vvGfnWUsoZY7OZwCaK7F1rG3V5pTZI7k4X60+DHzPT+1wwyfucO84K4tLfOJNh1dnf8I+Z5jZO/DGiwslW4NY+ZrO2euurlSDJFI5IqS4mkW1EJAd4HLjRGJPAGMdgjLkXuBdg3rx54b+rKANLeNqxn9HT4Osboq8vPc5Jo46j4o2BiJCTbquA0sIsSgut9Tl3fIHdYP0F8OijjG7bycs3n8a+hlZ27m/m9S2VjM3P4LhJI4AzWfGPNUwdk8O++lbOn1OMMVDZ0Movn3+P1zbvo8vATxZvICWYQltHG115G9hT28L63XV0GcOc0gJ27G9iXEEGk0dlMzY/k8KsVNo6uji2KY2JgJEAcspN7Hr1AR4ouJ5vp2V7lccnfu+d1GUPWteZn8PPsmndMz9m+0YgXqbfda/bfjGLnb5H/pihn0AATvyS/ZyWA0eca0Umv9QeD+NlcPmzw474iJ27BeyQNP5hQPxp8P5BRwMBL0EhZ7R3vNVOnCZnbOignW6syS9EItZ6dWcVjTRE0AGQTOEoA/xDiZYC4QPDRN1GRFKxovGwMeYfvm3KXXeWiBQDUQayUZRhyrzP2VeycTu5tTWQEgx09205fnKopfPodSdG2Bk+d/Jk2ju7uOflrWyvauLmc6dx1382c9+rHxAQ+MjMsRgD/9lYwaRRWbxbVsuz68rp7PLaeTcEy/lGKtzd8VEy6ubxP7uy6dzZxbv3LaWivpWSgkxH9DI5e8YYWnJOZkJ6FgXO/m0dXWxtzObwzz5NajBg+4CMmuq5m8bOsq/nbrUupJyx1mKJFcfILIAr/uZ9d+evd11yY2fZlv7Iw0PdTpNODRUOvxUQnjafNdKOeJw71vZb2rvG62iZOybUxez2a0nLsXHNM5xBK91zqNk+pITjbWCqiEwGdgGXA1eEbbMIuMGJf5wA1DqCIMAfgA3GmF9E2OczwO3O+5NJPAdFOXTJcToYuoN2JkgwIAQDQW48y2vF37ZwFiUFmUwelc2C2T2nF+jsMlQ1tLK/qY2mtk62flDMfjmOR96Yws6n1jNhRJYd5uX9/Zx2ZBHVjW08t3svVY1t/Py5TXQZKCnIJBgQ9je20dLeSUeXoSArldLCTE6YPJIxefmse3UVZ88Yw6SR2dQ2tzMnmE9uRzNvVKRw0nWvAbCmrJas9CBTimxix7rdtUwelU1WWli1mZplhcO1OE6+0WYspmaFdtCbfGrofoEY7qOJJ8K6J2wcbNTh8JlF8GtngE93WJgUZyRkN7YZTIGbP/COMXqGjbvEm56fAEkTDmNMh4jcADwLBIH7jTHrROQ6Z/09wGJgAbAFaALcZtTJwKeANSKy2ln238aYxVjBeFRErgZ2AJck6xwU5ZDn1qoDdon5CQSE608/POr6YEAYnZfB6Dzrrz9mQiFwDPcfWc+LGyu48oQJ1DS1U17XwrxJnuVT2dDK/3thM/mZqTyxahfjR1gLJD0lwMSRWSzfVs3u2mYeXLqdto4uctJTeHK15wBZlJbJnAB89u/bOXVNB6PzMnh0+U46uwxHjsllyuhsFq/Zy6SRWRw9oZCZ4/LITk9hZHYaZ6RkkgLUdqaSj/W116UVEwhAbkaql94cni7uWhyR+ict/I0NtI9yrlWh0+G2s9XrGPitrbHjRNkj4cQocbIDREz4BCfDkHnz5pnly5f3vqGiKMOaprYOdte0MHFkFmt21VJR10pOegonvHENKXtX8ZNZi3lxQwVlNc2cevgojplYyNL3q3hjaxUfPqKI8roWqhra2FvnZUk9k3Yz0wI7Ob/1JzSNnMm++lYaWjtITwlwybxSvlj/W9o6u1g2/Ttc8fRsylOKWbnwJSaMzGLK7qdIm/YR3tgD8yYVkpEapKW9kze2VpKRGuTEw0YirkVxzyk2u+q7+xIfuqiPiMgKY8y8HstVOBRFOeR55Q6bNnvJnwAwxngVNtDY2kFWWrB7WUV9C51dhl3VzeS+8C2OLPs7Dxz7OG/UFFCcn0lpYSZbKhr4x8pdtHV6Q/ock9/AntY09rR4MY0jxuTwXnkDR47JRQT2N7ZRUW+HXPnoUeM4Z+YYnl6zlzM238ZJqZt55LjH2FndzFnTxzjJCIb9jW1s2ltPS0cnm8sbOHJsLh8+oijkHPqCCocKh6IoyaCj1XZSdDvi+ahsaKWsupmCTOuWGpufQZcxvL+vke1VTbxbVsNflu3gzOmjeXtbNZNGZZGVlsLlx43nnbJa7l6yhfZOQ1pKgI9Pz2H55jK2tuYxMjudyoZWTj58JOt211HT1HOE3Ws/ZDtBfuXMqd3Zc4miwqHCoSjKICTcuvHT1NbB9qominLTGZWTTl1LOy1tnRRkpfH9RWt5Z2ct08bmMqsknymjc8hJt1ME/OTfG/jn6t0EA8I9Vx3L2TPGRDx+b6hwqHAoinKIUNfSzp3Pb+ajc8d5/XL6QDTh0NFxFUVRhhl5Gal878L+n4fDRefjUBRFURJChUNRFEVJCBUORVEUJSFUOBRFUZSEUOFQFEVREkKFQ1EURUkIFQ5FURQlIVQ4FEVRlIQ4JHqOi8g+oK+zto8CKvuxOAcbLf/AMZTLDlr+gWSwlH2iMaYofOEhIRwHgogsj9Tlfqig5R84hnLZQcs/kAz2squrSlEURUkIFQ5FURQlIVQ4eufegS7AAaLlHziGctlByz+QDOqya4xDURRFSQi1OBRFUZSEUOFQFEVREkKFIwYicq6IbBKRLSJyy0CXpzdEZJuIrBGR1SKy3Fk2QkSeF5HNznvhQJfTRUTuF5EKEVnrWxa1vCLybee/2CQiHxmYUntEKf8PRGSX8x+sFpEFvnWDpvwiMl5EXhKRDSKyTkS+6iwfEtc/RvmHyvXPEJG3ROQdp/w/dJYPieuPMUZfEV5AENgKHAakAe8AMwa6XL2UeRswKmzZT4FbnM+3AP830OX0le1DwDHA2t7KC8xw/oN0YLLz3wQHYfl/AHwjwraDqvxAMXCM8zkXeM8p45C4/jHKP1SuvwA5zudUYBkwf6hcf7U4onM8sMUY874xpg34K7BwgMvUFxYCDzifHwAuGriihGKMeQXYH7Y4WnkXAn81xrQaYz4AtmD/owEjSvmjMajKb4zZY4xZ6XyuBzYAJQyR6x+j/NEYbOU3xpgG52uq8zIMkeuvwhGdEmCn73sZsW/MwYABnhORFSJyrbNsjDFmD9iHDRg9YKWLj2jlHUr/xw0i8q7jynJdDYO2/CIyCTga2+odctc/rPwwRK6/iARFZDVQATxvjBky11+FIzoSYdlgz10+2RhzDHAecL2IfGigC9SPDJX/425gCjAX2AP83Fk+KMsvIjnA48CNxpi6WJtGWDYYyz9krr8xptMYMxcoBY4XkVkxNh9U5VfhiE4ZMN73vRTYPUBliQtjzG7nvQJ4AmvKlotIMYDzXjFwJYyLaOUdEv+HMabcqRC6gPvw3AmDrvwikoqtdB82xvzDWTxkrn+k8g+l6+9ijKkBlgDnMkSuvwpHdN4GporIZBFJAy4HFg1wmaIiItkikut+Bs4B1mLL/Blns88ATw5MCeMmWnkXAZeLSLqITAamAm8NQPli4j70Dh/D/gcwyMovIgL8AdhgjPmFb9WQuP7Ryj+Ern+RiBQ4nzOBs4CNDJHrPyAR+aHyAhZgszW2At8Z6PL0UtbDsFkX7wDr3PICI4EXgc3O+4iBLquvzI9g3Qnt2BbV1bHKC3zH+S82AecN0vI/CKwB3sU+7MWDsfzAKVhXx7vAaue1YKhc/xjlHyrXfw6wyinnWuB7zvIhcf11yBFFURQlIdRVpSiKoiSECoeiKIqSECociqIoSkKocCiKoigJocKhKIqiJIQKh6IMckTkNBF5aqDLoSguKhyKoihKQqhwKEo/ISJXOXMsrBaR3zmD2DWIyM9FZKWIvCgiRc62c0VkqTMY3xPuYHwicriIvODM07BSRKY4h88RkcdEZKOIPOz0nFaUAUGFQ1H6ARGZDlyGHWhyLtAJXAlkAyuNHXzyZeD7zi5/Bm42xszB9nR2lz8M/MYYcxRwErZnOtjRX2/EzstwGHBykk9JUaKSMtAFUJRhwpnAscDbjjGQiR2grgv4m7PNQ8A/RCQfKDDGvOwsfwD4uzPWWIkx5gkAY0wLgHO8t4wxZc731cAk4LWkn5WiRECFQ1H6BwEeMMZ8O2ShyK1h28Ua4yeW+6nV97kTfXaVAURdVYrSP7wIXCwio6F77uiJ2GfsYmebK4DXjDG1QLWInOos/xTwsrHzSZSJyEXOMdJFJOtgnoSixIO2WhSlHzDGrBeR72JnYAxgR8y9HmgEZorICqAWGwcBO2T2PY4wvA98zln+KeB3IvIj5xiXHMTTUJS40NFxFSWJiEiDMSZnoMuhKP2JuqoURVGUhFCLQ1EURUkItTgURVGUhFDhUBRFURJChUNRFEVJCBUORVEUJSFUOBRFUZSE+P8lfqDUU73+fAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##################\n",
    "# REPORTS\n",
    "##################\n",
    "reports.plotHistory( hist )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46e4430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Projects\\VenusDenoise\\saves\\0100_1000-64-convsim-g\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rdelasheras\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "model.save(os.path.abspath(os.path.join('../../../saves/', MODEL_NAME)), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd185317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
