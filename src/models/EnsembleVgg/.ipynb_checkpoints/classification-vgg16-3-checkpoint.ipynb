{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e37467bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Conv2D , MaxPooling2D, UpSampling2D, Conv2DTranspose, BatchNormalization, Activation, Add\n",
    "from tensorflow.keras.layers import ZeroPadding2D, Input, AveragePooling2D, Flatten, Dense, Dropout, concatenate\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "##################\n",
    "# IMPORTS\n",
    "##################\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow \n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('../../support/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "SAVE_MODEL = \"classification-vgg16-3\"\n",
    "    \n",
    "#https://towardsdatascience.com/galaxy-zoo-classification-with-keras-219184aff581    \n",
    "    \n",
    "import DatasetUtilsTifF as dsutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ebaf205",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width=64; img_height=64\n",
    "IMG_PATH = \"C:/Projects/VenusDenoise/dataset/cases/64/0100_1000/\"\n",
    "TRAIN_CLASSES_PATH = \"C:/Projects/VenusDenoise/out_tests/0100_1000-64-train7.csv\"\n",
    "VALID_CLASSES_PATH = \"C:/Projects/VenusDenoise/out_tests/train_classes/0100_1000-64-7.csv\"\n",
    "\n",
    "batch_size=16\n",
    "class RadianceLimits:\n",
    "    pass\n",
    "radiance_limits = RadianceLimits()\n",
    "radiance_limits.noisy_min = 0\n",
    "radiance_limits.noisy_max = 0.0898\n",
    "radiance_limits.nitid_min = 0\n",
    "radiance_limits.nitid_max = 0.3248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb634b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read dataset. Path: C:/Projects/VenusDenoise/dataset/cases/64/0100_1000/\n",
      "Noisy files:8738\n",
      "Nitid files:8738\n",
      "Read dataset. Path: C:/Projects/VenusDenoise/dataset/cases/64/0100_1000/validation/\n",
      "Noisy files:2208\n",
      "Nitid files:2208\n"
     ]
    }
   ],
   "source": [
    "train_files, train_classes, train_images = \\\n",
    "        dsutils.readDatasetClassification(IMG_PATH, img_width, img_height, radiance_limits, TRAIN_CLASSES_PATH)\n",
    "\n",
    "val_files, val_classes, val_images = \\\n",
    "    dsutils.readDatasetClassification(IMG_PATH + \"validation/\", img_width, img_height, radiance_limits, VALID_CLASSES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ef1dc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.reshape(train_images, (len(train_images), img_height, img_width, 1))  \n",
    "val_images= np.reshape(val_images, (len(val_images), img_height, img_width, 1))  \n",
    "\n",
    "#train_classes = train_classes.squeeze()\n",
    "#valid_classes = valid_classes.squeeze()\n",
    "\n",
    "train_classes= np.reshape(train_classes, (len(train_classes), 1))  \n",
    "val_classes= np.reshape(val_classes, (len(val_classes), 1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b05b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = tf.keras.utils.to_categorical( train_classes, num_classes=None, dtype='float32')\n",
    "val_classes = tf.keras.utils.to_categorical( val_classes, num_classes=None, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc993d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64, 64, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 64, 64, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2, 2, 4096)        2101248   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2, 2, 4096)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 65540     \n",
      "=================================================================\n",
      "Total params: 11,570,628\n",
      "Trainable params: 11,570,628\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input((img_width, img_height,1))\n",
    "\n",
    "conv1 = Conv2D(64, (3,3), activation='relu', padding='same')(input_layer)\n",
    "conv1 = Conv2D(64, (3,3), activation='relu', padding='same')(conv1)\n",
    "pool1 = MaxPooling2D((2,2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(128, (3,3), activation='relu', padding='same')(pool1)\n",
    "conv2 = Conv2D(128, (3,3), activation='relu', padding='same')(conv2)\n",
    "pool2 = MaxPooling2D((2,2))(conv2)\n",
    "\n",
    "conv3 = Conv2D(256, (3,3), activation='relu', padding='same')(pool2)\n",
    "conv3 = Conv2D(256, (3,3), activation='relu', padding='same')(conv3)\n",
    "pool3 = MaxPooling2D((2,2))(conv3)\n",
    "\n",
    "conv4 = Conv2D(512, (3,3), activation='relu', padding='same')(pool3)\n",
    "conv4 = Conv2D(512, (3,3), activation='relu', padding='same')(conv4)\n",
    "pool4 = MaxPooling2D((2,2))(conv4)\n",
    "\n",
    "conv5 = Conv2D(512, (3,3), activation='relu', padding='same')(pool4)\n",
    "conv5 = Conv2D(512, (3,3), activation='relu', padding='same')(conv5)\n",
    "pool5 = MaxPooling2D((2,2))(conv5)\n",
    "\n",
    "dense1 = Dense(4096, activation='relu')(pool5)\n",
    "dense1 = Dropout(0.5)(dense1)\n",
    "#dense2 = Dense(4096, activation='relu')(dense1)\n",
    "#dense2 = Dropout(0.5)(dense2)\n",
    "\n",
    "flatten = Flatten()(dense1)\n",
    "\n",
    "output_layer = Dense(4, activation = 'softmax')(flatten)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90200157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Nadam\n",
    "model.compile(optimizer=Nadam(learning_rate=0.00001), loss='categorical_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54978d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "547/547 [==============================] - 20s 27ms/step - loss: 1.1529 - accuracy: 0.4768 - val_loss: 1.2776 - val_accuracy: 0.4352\n",
      "Epoch 2/200\n",
      "547/547 [==============================] - 14s 26ms/step - loss: 1.0753 - accuracy: 0.5718 - val_loss: 1.3282 - val_accuracy: 0.4321\n",
      "Epoch 3/200\n",
      "547/547 [==============================] - 14s 26ms/step - loss: 1.0562 - accuracy: 0.5758 - val_loss: 1.2708 - val_accuracy: 0.4348\n",
      "Epoch 4/200\n",
      "547/547 [==============================] - 14s 26ms/step - loss: 1.0511 - accuracy: 0.5761 - val_loss: 1.2732 - val_accuracy: 0.4325\n",
      "Epoch 5/200\n",
      " 72/547 [==>...........................] - ETA: 12s - loss: 1.0632 - accuracy: 0.5625"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_images, train_classes, \n",
    "                        epochs=200,\n",
    "                        batch_size=16, \n",
    "                        verbose=1, \n",
    "                        validation_data=(val_images, val_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88b5a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# REPORTS\n",
    "##################\n",
    "import ReportsK as reports\n",
    "reports.plotHistory( hist )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0231376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95386097",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.abspath(os.path.join('../../../saves/', \"classification-vgg16-3\")), model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
